##verbatim '%' = MuPlugin.mumode

open Prelude
open Extra



let d = "{section "Polarised {muname}" ~label:s_pol}

Linear {muname} solves the weakening-against-weakening non-confluence example of Section {ref_ s_core}: to erase a variable, one must introduce a binder <%mu|_ _|,c%> which is not involved in a critical pair. However, there are still critical pairs of the form <%<mu x,c|mu y,c'>%> which can be typed in linear {muname}. It is conceivable that the reduction of linearly typed {muname} term is still non-confluent. And indeed, here is a counter-example.
{displaymath "<%<mu x,<(x,z)|v> | mu y,<(t,y)|w>>%>"}
which reduces both to
{displaymath "<% <(t,mu x,<(x,z)|v>)|w>%>
{qquad}and{qquad}
<%<(mu y,<(t,y)|w>,z)|v>%>"}
two distinct normal forms, yet has the following type:
{displaymath "<%;t:A,z:A^~,v:A^~`&A,w:A^~`&A|-<mu x,<(x,z)|v> | mu y,<(t,y)|w>>%>"}

There are several ways to think about this example. On the first hand, it could be said that the syntax is inadequate and we should move to a syntax which identifies both terms, like proof nets. On the other hand, we can also point out that <%mu x,c%> does not really make sense by itself: it is an active term which expects a counterpart. In that view, it does not really make sense to capture such a term in a pair <%(mu x,c,u)%> where the {mu} cannot be resolved.

{subsection"Restricting substitution"}

The solution suggested by the latter view is to take more seriously the distinction between {emph"values"} and {emph"computations"}. That is <%mu x,c%> is a computation, yet we take the point of view that variables should only be substituted with values. This is a form of {emph"call by value"}, even though, as we will see below, this does not preclude call by name functions. Such a restriction can be achieved by a syntactic criterion: identifying a syntactic class of values, and restricting reduction rules to only substitute values. This is the strategy used in the setting of {lambda}-calculus~{cite"Plotkin1975"} or in the original {muname} paper~{cite"Curien2000"}.

To offer a counter-point we will account for this restriction purely by typing. This is merely a difference in presentation, though, as the syntactic restriction can be read off directly from the typing rules. This idea leads to a {emph"polarised"} logic, where type are classified on whether their introduction rules are value constructors ({emph"positive"} types) or computation constructors ({emph"negative"} types). The restriction that variables can only be substituted with values then translates to the restriction that {emph"variables all are of positive type"}.

This rule has strong consequences: in <%mu(x,y),c%>, <%x%> and <%y%> must be of positive type, hence the two component of a pair must be values. In particular terms of the form <%(mu x,c,u)%>, like above, are no longer permissible. It is now well understood~{cite"Dyckhoff2006,Zeilberger2008,Munch2009,Curien2010"}, that this call-by-value restriction of sequent calculus is akin to focusing~{cite"Andreoli1992"}, though, on the details, it need not correspond too closely.

The classification of types is, hence, a strong restriction which we sum up with the following grammar, where <%A%> and <%B%> denote positive types and <%N%> and <%M%> denote negative types:
{displaymath begin syntax [
  syntax_line (`Other "<%A%>, <%B%>") Rules.Types.Polarised.positive;
  syntax_line (`Other "<%N%>, <%M%>") Rules.Types.Polarised.negative;
] end}
This grammar introduces two new dual connectives <%shiftn N%> and <%shiftp P%> -- both read ``shift'' -- to mediate between the two polarities.
(* This is not as interesting as I first thought
   Notice the two new types <%shiftn N%> and <%shiftp P%> which permit to embed positive and negative types into negative and positive types respectively. They both read ``shift''. Here again there was some amount of choice available: in Andreoli's treatment of focusing~{cite"Andreoli1992"}, every linear logic type is a valid type, the polarity only depends on the head connective and shifts are completely implicit (this approach is followed for {muname} in~{cite"Munch2009"}). In early {textsc"llp"} works~{citation}(* Olivier Laurent *), shifts were explicit, but conflated with the exponential connective <%!N%> was positive and <%?A%> was negative, it does not seem, however, easily amenable to the style of this article. In any case, the shift connectives have useful interpretations from a programming language perspective, which makes them interesting to study, hence their inclusion. *)
The shift connectives have reversed introduction rules, as <%shiftp P%> is introduced by the construction <%val v%> (read ``return'' <%v%>), and <%shiftn N%> by <%mu\(val x\),c%>, despite the former being negative and the latter positive. Indeed <%val v%> is a computation and <%mu\(val x\),c%> a value. Sequents for values are written <%Xi;Gamma|-_v t:A%>, this is purely cosmetic in this section, but the typing judgement of values and computations will be distinct in Section~{ref_ s_dep}.
{displaymath begin array [`C ; `Sep (qquad ^^ qquad) ; `C] [
  array_line [Rules.Typing.Fll.shiftn ; Rules.Typing.Fll.shiftp];
]end}
With the obvious reduction rule:
{displaymath (reduction Rules.Reduction.shift)}

As often, it is usually possible to define an alternative syntax to replace the {mu} pattern: <%shiftn N%> can alternatively be introduced by <%thunk t%> -- read ``thunk <%t%>'' -- defined as:
{displaymath "<%\(thunk t\) = mu\(val alpha\),<t|alpha> %>"}
The typing of which is given by:
{let open Infer in
 displaymath begin
   rule ~label:"definition"
     [rule ~label:negativeshift
         [rule ~label:(cutp"<%alpha%>")
             ["<%Xi;Gamma |- t:N%>"]
             "<%Xi;Gamma,alpha:N^~|-<t|alpha>%>"]
         "<%Xi;Gamma |-_v mu\(val alpha\),<t|alpha> : shiftn N%>"]
     "<%Xi;Gamma |-_v thunk t : shiftn N%>"
end}
And has as a reduction rule:
{displaymath "<%<thunk t | val u> ~~> <u|t>%>"}

{let sep = `Mm 2. in
 figurerules ~label:f_fll ~caption:"Polarised {muname}" [
   simple_block "Syntax" begin
     syntax [
       syntax_line `Term Rules.Syntax.(core@shift@multiplicative@additive@exponential);
       commands
     ]
   end;
   simple_block "Types" begin
     syntax [
       syntax_line (`Other "<%A%>, <%B%>") Rules.Types.Polarised.positive;
       syntax_line (`Other "<%N%>, <%M%>") Rules.Types.Polarised.negative;
     ]
   end;
   simple_block "Reduction" begin
     reduction Rules.Reduction.(core@shift@multiplicative@additive@exponential)
   end;
(*
   simple_block "Derived syntax" begin
     array [`L; symbsep $=$; `L] [
       array_line ["<%lambda x,t%>";"<%mu(x,alpha),<t|alpha>%>"];
       array_line ["<%t u%>"; "<%mu alpha, <t|(u,alpha)>%>"];
       array_line ["<%{1=t,2=u}%>"; "<%{mu(1.alpha),<t|alpha> , mu(2.alpha),<u|alpha>}%>"];
       array_line ["<%t.1%>"; "<%mu alpha,<t|1.alpha>%>"];
       array_line ["<%t.2%>"; "<%mu alpha,<t|2.alpha>%>"];
     ]
   end; *)
   block "Typing" [`C;`C] begin
     let open Rules.Typing.Fll in
         [
           block_line ~sep [ id ; cut ];
           block_line ~sep [ iddup ; mu ];
           block_line ~sep [ shiftn ; shiftp ; ];
           block_line ~sep [ pair ; copair ];
           block_line ~sep [ unit ; counit ];
           block_line ~sep [ iota1 ; case ];
           block_line ~sep [ iota2 ; empty];
           block_line ~sep [ zero ; emptycase ];
           block_line ~sep [ bang ; whynot ];
         ]
   end;
(*
   block "Derived typing rules" [`C;`C] begin
     let open Rules.Typing.Mall in
         [
           block_line ~sep [ lambda ; app ];
           block_line ~sep [ record ; pi1 ];
           block_line ~sep [ empty  ; pi2 ];
         ]
   end;
*)
 ]}

The other typing rules for polarised {muname} are given in Figure~{ref_ f_fll}. They are, actually, textually identical to the rules of linear {muname}, except that now <%A%> and <%B%> stand for positive types. Polarised {muname} is really only a matter of constraining the variables to have positive types.

The shift are not simple coercions between negative and positive types: they have a real computational significance. Indeed <%shiftp A%> is a bigger type than <%A%>: if <%A%> contains only values <%v%>, <%shiftp A%> contains any computation which {emph"evaluates to <%v%>"}. For instance, <%1%> only contains the value <%()%>, but <%shiftp 1%> contains computations like <%(lambda(),val ()) ()%>. In fact, polarised {muname} is a linear variant of Levy's call-by-push-value language~{cite"Levy2001"} ({textsc"cbpv"}. With <%shiftp A%> and <%shiftn N%> playing the role, respectively, of $F A$ and $U N$.

Like in {textsc"cbpv"}, computations can be chained, with the expression <%chain t x u%>, so that the value computed by <%t%> is bound to <%x%> in <%u%>, in a manner reminiscent of monadic composition.
{displaymath"<%chain t x u = mu alpha, < t | mu\(val x\), <u|alpha>>%>"}
with the same typing rule as in~{cite"Levy2001"} (up to linearity):
{let open Infer in
 displaymath begin
   rule ~label:"definition"
     [rule ~label:mu
         [rule ~label:cutrule
             ["<%Xi;Gamma|-t: shiftp A%>";
              rule ~label:negativeshift
                [rule ~label:(cutp"<%alpha%>")
                    ["<%Xi;Delta,x:A|- u : N%>"]
                    "<%Xi;Delta,alpha:N^~,x:A|- <u|alpha>%>"]
                "<%Xi;Delta,alpha:N^~|- mu\(val x\), <u|alpha>: shiftn A^~%>";]
             "<%Xi;Gamma,Delta,alpha:N^~|-< t | mu\(val x\), <u|alpha>>%>"]
         "<%Xi;Gamma,Delta|- mu alpha, < t | mu\(val x\), <u|alpha>> : N%>"]
     "<%Xi;Gamma,Delta|- chain t x u : N%>"
end}
Together with the reduction rule:
{displaymath"<%<chain \(val v\) x u | alpha> ~~> <subst[v,x] u| alpha>%>"}

Dually, the type <%shiftn N%> represents the type of suspended computations. A suspended computation differs from regular computation in that they can be stored in a value. Suspending a computation corresponds to an operation well-known to the functional programmer: building a closure. Indeed, a closure is nothing but packing a computation (typically in form of a code pointer) together with the environment necessary for the computation to be resumed later. That is, turning a computation into a value.

(* arnaud: ce paragraphe est trop bref, il faudra probablement y retourner *)
A feature shared by {textsc"cbpv"} and polarised {muname}, is that functions are computations <%A-oN%>. They are not made into closure unless they are suspended into the type <%shiftn(A-oN)%>. If closures are considered expensive to make, which they often are, this property can be useful as functions of multiple arguments <%A-oB-oC-oN%> do not need intermediate closures.

As a matter of fact, the Rust programming language has, for efficiency purposes, so-called {emph"stack closures"}, which are, in fact, not closures by that definition. Stack closures are functions which can be used only as argument of another function, and be called, but {emph"not"} be stored in a value. From the point of view of polarised {muname}, this would correspond to having variables of negative type, with restricted usage.

Suspended values, again inspired by {textsc"cbpv"}, can be turned back into computation with a <%force%> combinator:
{displaymath"<%force t = mu alpha, < t | val alpha>%>"}
Typed as
{let open Infer in
 displaymath begin
   rule ~label:"definition"
     [rule ~label:mu
         [rule ~label:cutrule
             ["<%Xi;Gamma|-_v t : shiftn N%>";
              rule ~label:positiveshift
                [rule ~label:idrule
                    []
                    "<%Xi;alpha:N^~ |-_v alpha:N^~%>"]
                "<%Xi;alpha:N^~ |- val alpha : shiftp N^~%>"]
             "<%Xi;Gamma,alpha:N^~ |- < t | val alpha >%>"]
         "<%Xi;Gamma |- mu alpha, < t | val alpha> : N%>"]
     "<%Xi; Gamma |- force t : N%>"
 end}
And with reduction rule:
{displaymath"<%<force \(thunk t\) | alpha> ~~> <t| alpha>%>"}

{subsection"Translations"}

Despite the call-by-value slant of polarised {muname}, both call-by-value and call-by-name {lambda}-calculus can be embedded in polarised {muname}. Again, all of the definitions are macros. For simplicity we will only give encoding of linear {lambda}-calculus, but the intuitionistic version is not very different. We use the definitions of <%lambda x,t%> and <%t u%> defined in Figure~{ref_ l_mall}, like the other connectives they have only changed inasmuch as the polarisation of the operands of the arrow type: the arrow <%A-oN = A^~`&N%> has positive domain and negative codomain. (* arnaud: ce dernier passage pourrait ^etre racont'e quand je parle de cl^otures plus haut *)

{subsubsection"Call-by-name {lambda}-calculus"} Call-by-name {lambda}-calculus is obtained by interpreting all type as being negative. As a consequence, all variables in the context must be shifted which modifies the variable rule, and the arrow is encoded as <%shiftn N -o M%>:
{let sep = `Mm 3. in
 let open Infer in
 let idenc =
   rule ~label:"force"
     [rule ~label:idrule [] "<%Gamma,x:shiftn N |-_v x:shiftn N%>"]
     "<%Gamma,x:shiftn N|-force x : N%>"
 in
 let appenc =
   rule ~label:apprule
     ["<%Gamma|-t : shiftn N -o M%>";
      rule ~label:negativeshift
        ["<%Delta|-u:N%>"]
        "<%Delta |-_v thunk u : shiftn N%>"]
     "<%Gamma,Delta|- t \(thunk u\) : M%>"
 in
 let absenc =
   rule ~label:lambda
     ["<%Gamma,x:shiftn N |- t : M%>"]
     "<%Gamma|- lambda x, t : shiftn N -o M%>"
 in
 displaymath begin array [`C] [
   array_line ~sep [idenc];
   array_line ~sep [appenc];
   array_line [absenc];
 ]end}

In call-by-name {lambda}-calculus, the arguments of functions are suspended so that their computation happens at use point: when the variables are used and forced. This translation, which is mostly forced by the choice that all types are interpreted as negative, happens to correspond closely to simple implementations, for instance Krivine's abstract machine.

{subsubsection"Call-by-value {lambda}-calculus"} Dually, in call-by-value {lambda}-calculus all of the types are interpreted as positive. Since a {lambda}-term is a computation, not a value, the type of the terms -- rather than the hypotheses as in call by name -- must be shifted. Also, the encoding of functions is a little more involved: <%shiftn(A-oshiftp B)%>. Again, this translation follows straightforwardly from the choice that every type is positive.
{let sep = `Mm 3. in
 let open Infer in
 let idenc =
   rule ~label:positiveshift
     [rule ~label:idrule [] "<%Gamma,x:A|-_v x:A%>"]
     "<%Gamma,x:A|-val x : shiftp A%>"
 in
 let appenc =
   rule ~label:"chain"
     ["<%Delta|-u:shiftp A%>";
      rule ~label:"chain"
        ["<%Gamma|-t : shiftp shiftn (A -o shiftp B)%>";
         rule ~label:"app"
            [rule ~label:"force"
                [rule ~label:idrule [] "<%f:shiftn (A-oshiftp B)|-_v f: shiftn (A-oshiftp B)%>"]
                "<%f:shiftn (A-oshiftp B)|- force f: A-oshiftp B%>";
             rule ~label:idrule
               []
               "<%x:A |-_v x:A%>"]
            "<%x:A,f:shiftn (A-oshiftp B)|- force f x : shiftp B%>"]
        "<%Gamma,x:A|-chain t f \(force f x\) : shiftp B%>";]
     "<%Gamma,Delta|- chain u x \(chain t f \(force f x\)\) : shiftp B%>"
 in
 let absenc =
   rule ~label:positiveshift
     [rule ~label:"thunk"
         [rule ~label:lambda
             ["<%Gamma,x:A |- t : shiftp B%>"]
             "<%Gamma|- lambda x, t : A -o shiftp B%>"]
         "<%Gamma|-_v thunk lambda x, t : shiftn (A -o shiftp B)%>"]
     "<%Gamma|- val thunk lambda x, t : shiftp shiftn (A -o shiftp B)%>"
 in
 displaymath begin array [`C] [
   array_line ~sep [idenc];
   array_line ~sep [appenc];
   array_line [absenc];
 ]end}

As in any call-by-value calculus, there is a non-canonical choice in the order of evaluation. We observe it in the translation of application: we chose to evaluate the argument before the function, but the reverse works just as well and behaves differently in presence of effects.

Notice that, contrary to the call-by-name {lambda}-calculus, the encoding of call-by-value {lambda}-calculus introduces a closure around every abstraction. This aspect is discussed, in the context of abstract machines, in~{cite"Leroy1990"~extra:"Chapter 3"}. Closures are usually expensive, hence we may want to eliminate intermediate closures in expressions of the form
{displaymath "<%val thunk lambda x,val thunk lambda y,t%>"}
(* arnaud: on veut probablement remettre ,ca sur une seule ligne *)
When it is applied to two arguments. It can be done by partial evaluation like in Section~{ref_ ss_optim}, because the application to two arguments <%u%> and <%v%>:
{displaymath"<%< chain v y \(chain (chain u x \(chain (val thunk lambda x,val thunk lambda y,t) f \(force f y\)\)) g \(force g x\)\) | alpha >%>"}
Is convertible to
{displaymath"<%< chain v y \(chain u x t\) | alpha >%>"}
It requires some care to avoid code duplication, however. Compared to the solution of the {textsc"zinc"} abstract machine~{cite"Leroy1990"~extra:"Chapter 3"}, this optimisation only applies to statistically detectable situation, whereas the {textsc"zinc"} tries dynamically to avoid intermediate closures. So partial evaluation of polarised {muname} is more efficient (as it forgoes dynamic tests), but does not apply as often.

(* proofs

<%< chain (chain t x u) y v | alpha >%>

<%< chain t x u | mu\(val y\), <v|alpha> >%>

<%< t | mu\(val x\), < u | mu\(val y\), <v|alpha> >>%>

{rule_ (`Mm 2.) (`Mm 2.)}

<%< chain t x \(chain u y v\) | alpha >%>

<%< t | mu\(val x\), < chain u y v | alpha >>%>

<%< t | mu\(val x\), < u | mu\(val y\), < v | alpha >>>%>

{rule_ (`Mm 2.) (`Mm 2.)}

<%< chain v x \(chain (chain u y \(chain t f \(force f y\)\)) g \(force g x\)\) | alpha >%>

<%< chain v x \(chain u y \(chain t f \(chain (force f y) g \(force g x\)\)\)\) | alpha>%>

{rule_ (`Mm 2.) (`Mm 2.)}

<% < chain (force (thunk lambda z, val thunk lambda w, t ) y) g \(force g x\) | alpha > %>

<% < chain ((lambda z, val thunk lambda w, t) y) g \(force g x\) | alpha > %>

<% < chain (val thunk lambda w, subst [y,z] t) g \(force g x\) | alpha > %>

<% < force (thunk lambda w, subst [y,z] t) x | alpha > %>

<% < (lambda w, subst [y,z] t) x | alpha > %>

<% < subst [y,z;x,w] t | alpha > %>

*)

{subsubsection"Call-by-value linear {muname}"} Like {lambda}-calculus, linear {muname} can be translated into polarised {muname}. There is the same dichotomy as for {lambda}-calculus with one translation interpreting each type as positive and another as negative.

Unlike {lambda}-calculus, types having all the same polarity causes difficulty because of the cut rule, and the {mu} rule. So, sadly, these are not macro-translations. To be fair, apart from the cut and {mu} rules, the terms are macro-translated, although their types are not. We will focus on the multiplicative fragment, the rest follows straightforwardly. We write <%[[A]]%> for the translation of type <%A%>.

In the encoding where all types are positive, the product <%A<*>B%> can be simply interpreted as <%[[A]]<*>[[B]]%>, and <%1%> as <%1%>. We can see, already, that this calculus will have a call-by-value feel. Like in call-by-value {lambda}-calculus, hypotheses have their bare type, but the type of the active term is shifted. Here is the identity rule
{let open Infer in
displaymath begin
  rule ~label:positiveshift
    [rule ~label:idrule [] "<%x:[[A]]|-_v x:[[A]]%>"]
    "<%x:[[A]]|-val x: shiftp [[A]]%>"
end}

When translating the type <%A^~`&B^~%>, we must construct a continuation of <%[[A<*>B]] = [[A]]<*>[[B]]%>, so basically we have no alternative but to choose <%[[A]]^~`&[[B]]^~%>, but since it's not a positive type, it needs to be shifted: <%[[A^~`&B^~]] = shiftn ([[A]]^~`&[[B]]^~)%>. Likewise, <%[[bot]] = shiftn bot%>.

Since cut and {mu} involve dualisation, they need to relate <%[[A]]%> and <%[[A^~]]%>. The property we deduce from the definition is: <%[[A^~]] = shiftn [[A]]^~%> or <%shiftp [[A^~]] = [[A]]^~%>. The cut rule must be oriented to recognise which of its operand has an extra shift.
{let open Infer in
displaymath begin
  rule ~label:cutrule
    [rule ~label:"thunk"
        ["<%Gamma|- t : shiftp [[A]]%>";]
        "<%Gamma|-_v thunk t : shiftn shiftp [[A]]%>";
     "<%Delta|- u : shiftp shiftn [[A]]^~%>"]
    "<%Gamma,Delta |- < thunk t | u >%>"
end}
The {mu} rule is worse, as it must be duplicated depending on whether it must add a shift or not to the selected hypothesis.
{let open Infer in
 let addshift =
   rule ~label:"definition"
     [rule ~label:positiveshift
         [rule ~label:negativeshift
             ["<%Gamma,x:[[A]]|- c%>"]
             "<%Gamma|-_v mu\(val x\), c : shiftn [[A]]^~%>"]
         "<%Gamma|- val mu\(val x\), c : shiftp shiftn [[A]]^~%>"]
     "<%Gamma|- val mu\(val x\), c : shiftp [[A^~]]%>"
 in
 let noshift =
   rule ~label:"definition"
     [rule ~label:mu
         ["<%Gamma,x:[[A]] |- c%>"]
         "<%Gamma |- mu x,c : [[A]]^~%>"]
     "<%Gamma|- mu x,c : shiftp [[A^~]]%>"
 in
 displaymath begin array [`C;`Sep (qquad^^qquad) ;`C] [
   array_line [ addshift ; noshift ]
 ]end}

The translation of introduction rules, on the other hand, are quite unproblematic. Pairing is obtained by first computing the values of the two components and then returning the pair of the obtained values. Like for call-by-value {lambda}-calculus, the order of evaluation is non-canonical.
{let open Infer in
 displaymath begin
   rule ~label:"chain"
     ["<%Delta|-v:shiftp [[B]]%>";
      rule ~label:"chain"
        ["<%Gamma|-u:shiftp [[A]]%>";
         rule ~label:positiveshift
           [rule ~label:tensor
               [rule ~label:idrule[]"<%y:[[A]]|-_v y:[[A]]%>";
                rule ~label:idrule[]"<%x:[[B]]|-_v x:[[B]]%>";]
               "<%x:[[B]],y:[[A]]|-_v (y,x) : [[A]]<*>[[B]]%>"]
           "<%x:[[B]],y:[[A]]|- val (y,x) : shiftp ([[A]]<*>[[B]])%>"]
        "<%Gamma,x:[[B]]|-chain u y \(val (y,x)\) : shiftp ([[A]]<*>[[B]])%>"]
     "<%Gamma,Delta|- chain v x \(chain u y \(val (y,x)\)\) : shiftp ([[A]]<*>[[B]])%>"
end}
A product continuation waits for the computation to be finished and continues with the two components
{let open Infer in
 displaymath begin
   rule ~label:positiveshift
     [rule ~label:"thunk"
         [rule ~label:parr
             ["<%Gamma,x:[[A]],y:[[A]] |- c %>"]
             "<%Gamma|- mu(x,y),c : [[A]]^~`&[[B]]^~%>"]
         "<%Gamma|-_v thunk mu(x,y),c : shiftn ([[A]]^~`&[[B]]^~)%>"]
     "<%Gamma|- val thunk mu(x,y),c : shiftp shiftn ([[A]]^~`&[[B]]^~)%>"
 end}
The introduction rules of nullary connectives <%1%> and <%bot%> are straightforward.

The small discrepancy which prevents this translation to be only done with macro is due to the fact that linear~{muname} is a single-sided sequent calculus. In a two-sided sequent calculus, the cut rule is already asymetric and their are two {mu}-binders: one for the left-hand side variables and one for the right-hand side variables. The call-by-value translation of a two-sided linear~{muname} has right-hand types translated to positive types, and left-hand types to negative types. This is loosely the same as the call-by-value restriction in the original system~{muname} paper~{cite"Curien2000"}.

{subsubsection"Call-by-name linear {muname}"} The negative translation of linear {muname} follows along the same lines. It has a call-by-name flavour, as witnessed by the identity rule
{let open Infer in
 displaymath begin
   rule ~label:"force"
     [rule ~label:idrule[]"<%x:shiftn N |-_v x:shiftn N%>"]
     "<%x:shiftn N|- force x : N%>"
end}
Hypotheses are shifted, and forced at use point. A product <%N<*>M%> is encoded as <%shiftp (shiftn [[N]] <*> shiftn [[M]])%>, so that a pair contains suspended computations:
{let open Infer in
 displaymath begin
   rule ~label:positiveshift
     [rule ~label:tensor
         [rule ~label:"thunk"
             ["<%Gamma|- u : [[N]]%>";]
             "<%Gamma|-_v thunk u : shiftn [[N]]%>";
          rule ~label:"thunk"
            ["<%Delta|- v : [[M]]%>";]
            "<%Delta|-_v thunk v : shiftn [[M]]%>";]
         "<%Gamma,Delta|-_v ( thunk u , thunk v ) : shiftn [[N]] <*> shiftn [[M]]%>"]
     "<%Gamma,Delta|- val ( thunk u , thunk v ) : shiftp (shiftn [[N]] <*> shiftn [[M]])%>"
end}
While a pair continuation, whose type is <%[[N^~`&M^~]] = shiftp[[N]]^~ `& shiftp[[M]]^~%>, binds the two (suspended) components of a product:
{let open Infer in
 displaymath begin
   rule ~label:parr
     ["<%Gamma,x:shiftn[[N]], y:shiftn[[M]]|-c%>"]
     "<%Gamma|-mu(x,y),c :  shiftp[[N]]^~ `& shiftp[[M]]^~%>"
 end}

(* arnaud: peut-^etre des notations plus coh'erentes dans la r`egle de cut, j'ai plus ou moins l'inverse de la d'efinition de la traduction ou N et M forment des paires alors que N^~ et M^~ forment des validations *)
For the cut rule, we proceed like in the call-by-value case: we have either <%[[N^~]]=shiftp [[N]]^~%> or <%shiftn [[N^~]] = [[N]]^~%>. The cut rule is oriented such that cutting with a pair continuation amounts to forcing the outermost pair constructor.
{let open Infer in
 displaymath begin
   rule ~label:cutrule
     ["<%Gamma|- u : shiftp [[N]]^~%>";
      rule ~label:"thunk"
        ["<%Delta|- v : [[N]]%>"]
        "<%Delta|-_v thunk v : shiftn [[N]]%>"]
     "<%Gamma,Delta|- < u | thunk v >%>"
end}
Like in the call-by-value translation, the {mu} rule is duplicated:
{let open Infer in
 let direct =
   rule ~label:"definition"
     [rule ~label:negativeshift
         ["<%Gamma,x:shiftn [[N]]|- c%>"]
         "<%Gamma|-_v mu  x, c : shiftp [[N]]^~%>"]
     "<%Gamma|- mu x, c : [[N^~]]%>"
 in
 let chain =
   rule ~label:"chain"
     [rule ~label:"force"
         [rule ~label:idrule[]"<%y:shiftn [[N^~]]|- y : shiftn [[N^~]]%>"]
         "<%y:shiftn [[N^~]]|- force y : [[N^~]]%>";
      rule ~label:"definition"
        [rule ~label:mu
            ["<%Gamma,x:shiftn [[N]] |- c%>"]
            "<%Gamma |- mu x,c : shiftp [[N]]^~%>"]
        "<%Gamma|- mu x,c : shiftp shiftn [[N^~]]%>";]
     "<%Gamma|- chain \(mu x,c\) y \(force y\) : [[N^~]]%>"
 in
 displaymath begin array [`C;`Sep (qquad^^qquad) ;`C] [
   array_line [ direct ; chain ]
 ]end}

The evaluation strategy of the negative translation of linear {muname}, evaluating the outermost constructor on demand, is essentially the same behaviour as lazy programming language such as Haskell (except that lazy programming languages have a call-by-need strategy, hence suspended computations must be shared rather than duplicated).

Like in the call-by-value case, if we translated a two-sided sequent calculus, we would obtain a macro-translation. And it would correspond to the call-by-name calculus of~{cite"Curien2000"}.
(* arnaud: cette section a potentiellement besoin d'un peu de mise en page tout de m^eme *)

"
