(* -*- compile-command: "ocamlbuild -classic-display dissect.pdf && evince _build/dissect.pdf" -*- *)

##verbatim '%' = MuPlugin.mumode

open Prelude


let symbsep s = `Sep ${quad}{s}{quad}$
let syntax_line k ?(extend=false) l =
  let k = match k with
    | `Term -> "<%t%>, <%u%>"
    | `Command -> "<%c%>"
  in
  let l = if extend then ldots::l else l in
  array_line [ k ; concat_with_sep l mid ]
let commands = syntax_line `Command ["<%<t|u>%>"]
let syntax l = array [`L;symbsep grammardef; `L] l
let reduction l = array [`L; symbsep leadsto; `L] l
(* arnaud: note, la fonte pour sans serif (textsf) a l'air de n'être
   pas à la même taille que celle de la fonte romane… ça n'est
   pas très beau. *)

(*** doc ***)
let abstract = "There will be an abstract some day."

let intro = "{section' "Foreword"}

In this article I will discuss typing of a calculus -- or, to be
fair, a family of calculus -- I call {mu}. It originates from a
paper by Herbelin \& Curien~{citation_needed}, where it was
called ${bar lambda}{mu}{tilde mu}$-calculus. It has since been
often called simply ${mu}{tilde mu}$, or system L
syntax~{citation_needed}. The latter name comes from
proof-theoretical investigations, this article has more a programming
language feel, and we will not see a {tilde mu}. Hence just {mu}.

The {foreign "tour de force"} of {mu}, in my opinion, is to provide
a syntax for classical sequent calculus proofs in which, like {lambda}-calculus
for natural deduction, contraction and weakening are done through
variables: a bound variable which isn't used is weakened, if it is
used twice or more it is contracted. This is, I would argue, why
it makes a good foundation for a programming language.

To me at least, the appeal of sequent calculus is hard to resist. It
has a more symmetric structure than natural deduction, and proof search
is more naturally expressed in it. Importantly for this article, Lengrand
has shown~{citation_needed} that proof search is expressed naturally
in a dependently typed (intuitionist) sequent calculus.

The object of this paper, is to study {mu} as a programming language whose
typing rules correspond to linear sequent calculus. And then to add dependent
types to the mix. The main motivation is to use this calculus as a stepping
stone to understand mathematics in presence of computational effects (as
linear logic can be used, to some extent, to model effects~{citation_needed}).
I also hope to use dependent linear {mu} as a new lense through which
usual dependently typed language could be further analysed.
The choice of linear logic rather than some flavour of intuitionist linear
logic might be a matter of taste, I tend to favour symmetry when I can; it
was originally a challenge as well, as dependent types are somewhat antagonistic
to the kind of commutation sequent calculus allow. In retrospect, though,
it may very well be that linear dependent types are easier -- at least using
{mu} as a framework -- than intuitionist linear dependent types.
"

let coremu = "{section "Core {mu}"}

Stripped down to its bare minimum, {mu} appears as a very simple calculus whose
syntax is made of two kinds of objects, terms (<%t%>, <%u%>, <%v%>) and commands
(<%c%>)
{displaymath begin syntax [
  syntax_line `Term Rules.Syntax.core;
  commands
] end}
Together with reduction rules
{displaymath begin reduction [
  Rules.Reduction.mu;
  array_line [ "<%<mu x,c|t>%>" ; "<%subst [t,x] c%>" ];
] end}
The intent being that the vertical bar be read as commutative. We shall using
as such from now on.

Given a command <%c%>, the term <%mu x, c%> can be thought as ``let <%x%> be
the current continuation, do <%c%>''. Conversely, for two terms, <%t%> and <%u%>
<%<t|u>%> runs <%t%> with continuation <%u%> (or symmetrically, <%u%> with
continuation <%t%>) it is read ``<%t%> against <%u%>''.
Terms reduce to a value, whereas command just compute -- they are played only
for there effects. Though it is possible to imagine otherwise, and consider
{textsc"io"} of sorts, the only effects available to a computation in pure {mu}
is returning to a continuation.

The reduction rules look quite similar to {beta}-reduction,
however this core calculus does not have nearly the power of {lambda}-calculus.
Indeed the fact that there are two kinds of object is crucial here: from a
functional programming perspective, it is like if the only construct was
{textsf"let{ldots}in"}. Contrary to {lambda}-calculus we have practically no
computation power without additional constructs.

Nonetheless, we can already observe undesirable behaviours. For instance it is easy to
cook up a non-terminating command <%<mu x,<x|x> | mu x,<x|x>>%>.
Much worse: any two commands <%c_1%> and <%c_2%> are redux of a common command
<%<mu alpha, c_1 | mu alpha, c_2>%> where <%alpha%> is fresh. (*arnaud: essayer de regarder les conflits contraction/contraction et weakening/contraction*)

{subsection "Typing as classical sequent calculus"}

The original typing rules~{citation_needed} for {mu} corresponded closely to classical
sequent calculus. We shall present, here, a one-sided version of them. Core mu does not
have any connective, however as is necessary in a one-sided sequent calculus, we shall
assume that every formula <%A%> has a dual <%A^~%>, and that <%A^~^~%> is <%A%> itself.

There are two kinds of sequents, one for each kind of objects: terms are typed with
sequent of the form
{displaymath "<%Gamma|-t:A%>"}
and commands with sequents
{displaymath "<%Gamma|-c%>"}

Readers familiar with one-sided sequent calculi might wonder why we used this particular
form for sequents. It was chosen mostly for its resemblance to natural deduction sequents,
more familiar in the realm of programming languages; also it allows variables to appear
with the same type in terms and in the context.

The three typing rules for classical core {mu} are the identity rule, giving their type
to variables
{displaymath Rules.Typing.Mall.id}
the {mu} rule, for {mu} abstractions
{displaymath Rules.Typing.Mall.mu}
and the cut rule giving their types to interactions
{displaymath Rules.Typing.Mall.cut}
where the context is considered up to commutation of the comma.

What should be taken away from these rules is that the identity and cut rules are sufficient
to make weakening and contraction admissible. It is also the case that reduction is terminating,
as terms like the aforementioned <%<mu x,<x|x> | mu x,<x|x>>%> cannot be typed. On the other hand,
non-confluence is still as acute as the following derivation demonstrates:
{displaymath begin
  Infer.rule [
       Infer.rule [Infer.rule [] "<%Gamma,alpha:A^~|- c_1%>"] "<%Gamma|-mu alpha,c_1 : A%>";
       Infer.rule [Infer.rule [] "<%Gamma,beta:A|- c_2%>"] "<%Gamma|-mu beta,c_2 : A^~%>"]
  "<%Gamma|-<mu alpha,c_1|mu beta, c_2>%>"
end}
Hence, by the weakening property, if <%c_1%> and <%c_2%> are both typable in <%Gamma%>, then they are
redux of a common typable term in <%Gamma%>. This is, in fact, nothing more than the classical
weakening-weakening critical pair of cut elimination.

{subsection "Typing as linear sequent calculus"}
To address the confluence issue, we move from a classical sequent calculus. In the case of core
{mu} this simply requires simple modifications of the identity rule
{displaymath (Infer.rule ~label:idrule [] "<%x:A|-x:A%>")}
and cut rule
{displaymath (Infer.rule ~label:cutrule ["<%Gamma|-t:A%>";"<%Delta|-u:A^~%>"] "<%Gamma,Delta|-<t|u>%>")}
to prevent weakening and contraction to happen. The {mu} rules stays as above.

Would we to limit the exchange of formul{ae} in the context, we could play with the {mu} rule. We shall, however,
keep reading the comma as commutative.
"

        let llmu = "{section "Linear {mu}"}
As mentioned in the previous section, core {mu} does not have all that much computing abilities.
This has much to do with the fact that its typing rules don't involve any connectives.
In this section we shall extend {mu} constructs to reflect the whole range of linear logic
connectives.

{subsection "Multiplicative fragment"}
The multiplicative connectives <%A<*>B%> and <%A`&B%> are reflected in the syntax as two
term constructors
{displaymath begin syntax [
  syntax_line `Term ~extend:true Rules.Syntax.([ pair ; copair ]);
] end}
a pairing construct, and a pair elimination construct whose reduction rule is
{displaymath begin reduction [
  Rules.Reduction.pair
] end}
In a pattern that will repeat itself throughout this article, the tensor product
is a {emph"positive"} construction, and its proofs are, hence, built out of terms, and the
par is a {emph"negative"} construction and its proofs are built out of command, and have
a pattern-matching feel.

The corresponding typing rules are fairly straightforward
{displaymath Rules.Typing.Mall.pair}
{displaymath Rules.Typing.Mall.copair}

Using these rules, we can encode the somewhat more familiar constructs of (linear) {lambda}-calculus. Writing,
as usual, <%A-oB%> for <%A^~`&B%> we get abstraction
{displaymath (Infer.rule ~label:parr [Infer.rule ~label:cutrule ["<%Gamma,x:A|-t:B%>";Infer.rule ~label:idrule [] "<%alpha:B^~|-alpha:B^~%>"]
                                           "<%Gamma,x:A,alpha:B^~|-<t|alpha>%>"]
                 "<%Gamma|-mu(x,alpha),<t|alpha>:A-oB%>")}
and application
{displaymath (Infer.rule ~label:mu [Infer.rule ~label:cutrule ["<%Gamma|-t:A-oB%>";Infer.rule ~label:tensor ["<%Delta|-u:A%>";Infer.rule ~label:idrule [] "<%alpha:B^~|-alpha:B^~%>"] "<%Delta,alpha:B^~|-(u,alpha):A<*>B^~%>"] "<%Gamma,Delta,alpha:B^~|- <t|(u,alpha)>%>"] "<%Gamma,Delta|-mu alpha, <t|(u,alpha)> : B%>")}

We shall henceforth write <%lambda x,t%> for <%mu(x,alpha),<t|alpha>%> and <%t u%> for <%mu alpha, <t|(u,alpha)>%>.
Apart from systematically deriving them from their desired typing rules, as above, the best way to understand these two derived construct is via abstract machines. Indeed, reading alpha as {emph"the stack"}, the application reads
``play <%t%> against the stack augmented by <%u%>'', this is the {emph"push"} instruction of abstract machines.
Abstraction, dually, reads as ``let <%x%> be the top of the stack, play <%t%> against the rest of the stack'',
that is, the {emph"grab"} instruction of virtual machines. The reader can satisfy himself that {beta}-reduction
is correctly simulated by the reduction rules of {mu}, {foreign"i.e."} for any term <%v%>,
<%<(lambda x, t) u|v> ~~> <subst [u,x] t| v>%>.

The correspondence with abstract machines is no coincidence, and we shall encounter it again. It can be
viewed as a consequence of the fact that, through its core construction, {mu} internalises the notion of
stack. In fact, when writing an abstract machine for {mu} there is no need of an explicit stack, everything
stack-like is taken care of by the multiplicative constructs.

(* arnaud: On pourrait penser à parler un peu des deux vues, quand A<*>B est le terme et A`&B le contexte
   et vice-versa *)

{subsection "Additive fragment"}

Additive type constructors include <%A<+>B%> and <%A&B%>, where the former is positive, hence built out
of terms and the latter negative and built out of commands. They are used to implement case analysis,
with a term of type <%A<+>B%> is pattern-matched by the term of type <%A^~&B^~%> it is played against.
Dually, a term of type <%A&B%> can be seen as a {emph"record"} and a term of type <%A^~<+>B^~%> provides
the projection (together with its continuation).

The syntax of their terms is as follows
{displaymath begin syntax [
  syntax_line `Term ~extend:true Rules.Syntax.([iota1;iota2;case])
] end}
and comes with the reduction rules
{displaymath begin reduction Rules.Reduction.([ iota1 ; iota2 ]) end}
{let l_mall = label ~name:\"figure:mall\" () in
"The typing rules are fairly straightforward. The whole multiplicative and additive fragment can
be found in Figure {ref_ l_mall}.

As for the multiplicative fragment, we can define useful derived term constructors. To better
encode records, we write <%{1=t,2=u}%> for <%{mu(1.alpha),<t|alpha> , mu(2.alpha),<u|alpha>}%>
(with <%alpha%> fresh). The projections are <%t.1%> and <%t.2%>, and stand for
<%mu alpha,<t|1.alpha>%> and <%mu alpha,<t|2.alpha>%>, respectively.

{let sep = `Mm 2. in
 figurerules ~label:l_mall ~caption:"Multiplicative and additive fragment" [
   simple_block "Syntax" begin
     syntax [
       syntax_line `Term Rules.Syntax.(core@multiplicative@additive);
       commands
     ]
   end;
   simple_block "Reduction" begin
     reduction Rules.Reduction.(core@multiplicative@additive)
   end;
   simple_block "Derived syntax" begin
     array [`L; symbsep $=$; `L] [
       array_line ["<%lambda x,t%>";"<%mu(x,alpha),<t|alpha>%>"];
       array_line ["<%t u%>"; "<%mu alpha, <t|(alpha,u)>%>"];
       array_line ["<%{1=t,2=u}%>"; "<%{mu(1.alpha),<t|alpha> , mu(2.alpha),<u|alpha>}%>"];
       array_line ["<%t.1%>"; "<%mu alpha,<t|1.alpha>%>"];
       array_line ["<%t.2%>"; "<%mu alpha,<t|2.alpha>%>"];
     ]
   end;
   block "Typing" [`C;`C] begin
     let open Rules.Typing.Mall in
         [
           block_line ~sep [ id ; cut ];
           block_line ~sep [ mu ; empty ];
           block_line ~sep [ pair ; copair ];
           block_line ~sep [ unit ; counit ];
           block_line ~sep [ iota1 ; case ];
           block_line ~sep [ iota2 ; empty];
           block_line ~sep [ emptycase ; zero ];
         ]
   end;
   block "Derived typing rules" [`C;`C] begin
     let open Rules.Typing.Mall in
         [
           block_line ~sep [ lambda ; app ];
           block_line ~sep [ record ; pi1 ];
           block_line ~sep [ empty  ; pi2 ];
         ]
   end;
 ]}

{subsection "Exponentials"}
The typing rules presented so far are purely linear, in the sense that there is no contraction
-- or weakening -- happening. For instance, the term <%(x,x)%> can be given a type in no context.
In~{citation_needed} this is solved by the following rule:
{displaymath (Infer.rule ["<%Gamma,x:!A,y:!A|-t:B%>"] "<%Gamma,x:!A|-subst [x,y] t : B%>")}
To this author, though, it feels like dodging the issue, somewhat. Indeed, it makes
<%x:!A|-(x,x):!A<*>!A%> a correctly typed sequent, however, it does not really delegate
contraction to variables, as type derivations need to linearise terms appropriately before
contexts are split. Additionally, in traditional calculi, including {mu}, if one wants to
contract to variables of the same type, they have to introduce an explicit construction
(in {lambda}-calculus: <%(lambda x y, t) x x%>), so at the same time this rule is somewhat
too strong.

Instead, we shall choose, here, to use the dyadic presentation of linear logic, first introduced
by Andreoli~{citation_needed}, where duplicable formul{ae} are rendered in an separate context.
This choice happens to have non-trivial consequences: in~{citation_needed}, <%!A%> is built out
of commands, whereas <%?A%> was built out of terms, in the version presented here, it is
the opposite. (*arnaud: ma version est la version plus décomposée de l'exponentielle, mais
pour en discuter il faudrait que je trouve quelque chose de concret à citer*)
The syntax is
{displaymath (syntax [
  syntax_line ~extend:true `Term Rules.Syntax.exponential
])}
and the associated reduction rule
{displaymath (reduction [
  Rules.Reduction.exponential
])}

The typing judgement are now of the form <%Xi;Gamma|-t:A%> and <%Xi;Gamma|-c%>, where
<%Gamma%> is the linear context as earlier, and <%Xi%> is the new context, containing
duplicable formul{ae}, which can be contracted and weakened. Contracting and weakening,
as in classical {mu} are handled implicitly, by duplicating <%Xi%> at forks {foreign"e.g."}
{displaymath Rules.Typing.Ll.cut}
and dropping <%Xi%> at leaves {foreign"e.g."}
{displaymath Rules.Typing.Ll.id}

We also need an extra structural rule to be able to use formul{ae} in <%Xi%>. This is
usually given in form of the {emph"copy"}, or {emph"absorbtion"}, rule:
(*arnaud: penser à rajouter une règle dans le parser pour ne rien avoir après le |-,
  ce sera mieux pour l'alignement *)
{displaymath (Infer.rule ["<%Xi,A;Gamma|-A^~%>"] "<%Xi,A;Gamma|-%{phantom$a$}%%>")}
where formul{ae} in <%Gamma%> are reverted into <%Xi%>. We shall, however, prefer a variant
of the identity function:
{displaymath Rules.Typing.Ll.iddup}
it allows to see variables in <%Xi%> as regular variables which can be used any
number of times. We can recover the copy rule using a cut:
{displaymath begin
  Infer.rule ~label:cutrule
    ["<%Xi,x:A;Gamma|-t:A^~%>";
     Infer.rule ~label:iddup [] "<%Xi,x:A; |- x:A%>"]
    "<%Xi,x:A;Gamma|-< t | x >%>"
end}

The introduction rule for <%!A%> corresponds to the promotion rule of linear logic,
{foreign"i.e."} a term of type <%A%> can be promoted to type <%!A%> is all its variables
are duplicable:
{displaymath Rules.Typing.Ll.bang}

The introduction rule for <%?A%> corresponds to the dereliction rule:
{displaymath Rules.Typing.Ll.whynot}

{let l_ll = label ~name:\"figure:ll\" () in
 let l_lambda = label ~name:\"figure:lambda\" () in
"The rest of the typing rules are barely affected. They can be found in Figure {ref_ l_ll}, along with the full description of the system.
{let sep = `Mm 3. in
 figurerules ~label:l_ll ~caption:"Linear {mu}" [
   simple_block "Syntax" begin
     syntax [
       (* arnaud: on va probablement avoir besoin d'aller à la ligne ici pour
          éviter l'overfull box *)
       syntax_line `Term Rules.Syntax.(core@multiplicative@additive@exponential);
       commands
     ]
   end;
   simple_block "Reduction" begin
     reduction Rules.Reduction.(core@multiplicative@additive@[exponential])
   end;
   block "Typing" [`C;`C] begin
     let open Rules.Typing.Ll in
         [
           block_line ~sep [ id ; cut ];
           block_line ~sep [ iddup ; mu ];
           block_line ~sep [ pair ; copair ];
           block_line ~sep [ unit ; counit ];
           block_line ~sep [ iota1 ; case ];
           block_line ~sep [ iota2 ; empty];
           block_line ~sep [ emptycase ; zero ];
           block_line ~sep [ bang ; whynot ]
         ]
   end;
 ]
}

(* arnaud: je ne crois pas que j'ai parlé de la séquentialisation de contextes *)
(* arnaud: je crois que le commentaire précédent fait référence au nesting de pattern.
           Et que je devais être dans un sale état. *)
(* arnaud: même remarque que plus bas: le nesting de pattern dans le lambda est pas
           aussi trivial que je veux bien le faire croire. Justifier que la syntaxe
           donnée dans ce paragraphe est correcte. *)
An noticeable property of the duplicable context, is that it behaves just as the context
in natural deduction sequents. That is, typing derivation bottom up, it only grows as the
derivation progresses, and is dropped
at the leaves. No other manipulation are performed. As a consequence, we can embed quite literally simply
typed {lambda}-calculus in linear {mu}, see Figure {ref_ l_lambda}.
{let sep = `Mm 3. in
 figurerules ~label:l_lambda ~caption:"Embedding {lambda}-calculus" [
    block "Typing" [`C;`C] [
       block_line ~sep [ 
          Infer.rule [] "<%Xi,x:A;|-x:A%>";
          empty
       ];
       block_line ~sep [
          Infer.rule ["<%Xi,x:A;|- t:B%>"] "<%Xi;|-lambda |_x_|, t : !A-oB%>";
          Infer.rule ["<%Xi;|-t:!A-oB%>";"<%Xi;|-u:A%>"] "<%Xi;|-t |_u_| : B%>";
       ];
    ]
 ]
}

"}
"}"

let examples = "{section"Using {mu}"}
  (* arnaud: j'écrirai le baratin plus tard *)
  (* arnaud: les patterns avec lambda ne fonctionnent pas bien (dans le sens où ils ne
             sont pas macro-expressibles en terme de lambda. Ils se comportent comme
             prévu, mais le typage est chiant à écrire. *)

  Isomorphism between <%!(A&B)%> and <%!A<*>!B%>:
  {displaymath $"<%phi%>"="<%lambda |_x_|, (x.1,x.2)%>"$}
  typed as
  {displaymath begin
    Infer.rule ~label:parr
       [Infer.rule ~label:cutrule
           [ Infer.rule ~label:whynotrule
               [ Infer.rule ~label:cutrule
                   [ Infer.rule ~label:tensor
                        [ Infer.rule ~label:bangrule
                             [ Infer.rule ~label:pi1rule
                                 [ Infer.rule ~label:iddup [] "<%x:A&B;|-x:A&B%>"] 
                                 "<%x:A&B;|- x.1 : A%>" ]
                             "<%x:A&B;|- |_x.1_| : !A%>";
                          Infer.rule ~label:bangrule
                             [ Infer.rule ~label:pi2rule
                                 [ Infer.rule ~label:iddup [] "<%x:A&B;|-x:A&B%>"]
                                 "<%x:A&B;|- x.2 : B%>" ]
                             "<%x:A&B;|- |_x.2_| : !B%>"]
                        "<%x:A&B; |- (|_x.1_|,|_x.2_|) : !A<*>!B%>";
                    Infer.rule ~label:idrule [] "<%;beta:?A&?B|-beta:?A&?B%>"]
                   "<%x:A&B;beta:?A`&?B |- <(|_x.1_|,|_x.2_|)|beta>%>"]
               "<%;beta:?A`&?B|- mu |_x_|,<(|_x.1_|,|_x.2_|)|beta> : ?(A<+>B) %>";
             Infer.rule ~label:idrule [] "<%;alpha:!(A&B) |- alpha:!(A&B)%>"]
           "<%;alpha:!(A&B),beta:?A`&?B |- <mu |_x_|,<(|_x.1_|,|_x.2_|)|beta>|alpha> %>"]
       "<%|- lambda |_x_|, (|_x.1_|,|_x.2_|) : !(A&B) -o !A<*>!B %>"
  end}
  and
  {displaymath $"<%phi^\(-1\)%>"="<%lambda (|_a_|,|_b_|), |_{ 1= a , 2= b }_|%>"$}
  typed as
  (* arnaud: je ne me tappe pas la preuve que lambda-pattern se comporte bien, cette fois-ci *)

"

(* maintenant on veut écrire quelques programmes en mu *)
(* après on veut parler de confluence *)

let d = concat [
  intro;
  coremu;
  llmu;
  examples;
]

let _test = "{Infer.rule ~label:(mathrm $Dummy$) ["<%<mu x, c|y>%>"] "<%A<*>B%>"}"
      
(*** boilerplate ***)

let title = "Dissecting {mu}"
let authors = [
  { name = "Arnaud Spiwack";
    email = Some "arnaud@spiwack.net";
    address = "Inria -- {textsc "pps"} -- Université Paris Diderot, France"
  };
]

let keywords = [
  "Sequent calculus";
  "Dependent types";
  "Linear logic";
  "Focusing";
(*  "μμ̃"; Confuses latex *)
]

let acmclass = [
  "F.3.1"; (* (un peu douteux) Specifying, and verifying and reasoning about programs http://dl.acm.org/ccs.cfm?part=author&coll=DL&dl=ACM&row=F.3.1&idx=6&idx2=F.3.1&idx3=3&query=Subject%3A%22Logics%20of%20programs%22&CFID=83889239&CFTOKEN=84492988 *)
  "F.3.3"; (* (moins douteux) Studies of program constructs http://dl.acm.org/ccs.cfm?part=author&coll=DL&dl=ACM&row=F.3.3&idx=6&idx2=F.3.3&idx3=5&query=Subject%3A%22Type%20structure%22&CFID=83889239&CFTOKEN=84492988 *)
]

let packages = [
  "inputenc" , "utf8" ;
  "fontenc" , "T1" ;
  "textcomp", "";
  "microtype" , "" ;
]

let prelude = concat_with_sep [] par

let file = \"dissect.tex\"

let _ = emit ~file (document
		             ~title
			     ~authors
                             ~keywords
                             ~acmclass
			     ~prelude
			     ~packages
                             ~abstract
			     d)
