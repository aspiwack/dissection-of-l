##verbatim '%' = MuPlugin.mumode

open Prelude
open Extra



let d = "{section "Polarised {muname}" ~label:s_pol}

Linear {muname} solves the weakening-against-weakening non-confluence example of Section {ref_ s_core}: to erase a variable, one must introduce a binder <%mu|_ _|,c%> which is not involved in a critical pair. However, there are still critical pairs of the form <%<mu x,c|mu y,c'>%> which can be typed in linear {muname}. It is conceivable that the reduction of linearly typed {muname} term is still non-confluent. And indeed, here is a counter-example.
{displaymath "<%<mu x,<(x,z)|v> | mu y,<(t,y)|w>>%>"}
which reduces both to
{displaymath "<% <(t,mu x,<(x,z)|v>)|w>%>
{qquad}and{qquad}
<%<(mu y,<(t,y)|w>,z)|v>%>"}
two distinct normal forms, yet has the following type:
{displaymath "<%;t:A,z:A^~,v:A^~`&A,w:A^~`&A|-<mu x,<(x,z)|v> | mu y,<(t,y)|w>>%>"}

There are several ways to think about this example. On the first hand, it could be said that the syntax is inadequate and we should move to a syntax which identifies both terms, like proof nets(*arnaud:citation?*). On the other hand, we can also point out that <%mu x,c%> does not really make sense by itself: it is an active term which expects a counterpart. In that view, it does not really make sense to capture such a term in a pair <%(mu x,c,u)%> where the {mu} cannot be resolved.

{subsection"Restricting substitution"}

The solution suggested by the latter view is to take more seriously the distinction between {emph"values"} and {emph"computations"}. That is <%mu x,c%> is a computation, yet we take the point of view that variables should only be substituted with values. This is a form of {emph"call by value"}, even though, as we will see below, this does not preclude call by name functions. Such a restriction can be achieved by a syntactic criterion: identifying a syntactic class of values, and restricting reduction rules to only substitute values. This is the strategy used in the setting of {lambda}-calculus~{cite"Plotkin1975"} or in the original {muname} paper~{cite"Curien2000"}.

To offer a counter-point we will account for this restriction purely by typing. This is merely a difference in presentation, though, as the syntactic restriction can be read off directly from the typing rules. This idea leads to a {emph"polarised"} logic, where type are classified on whether their introduction rules are value constructors ({emph"positive"} types) or computation constructors ({emph"negative"} types). The restriction that variables can only be substituted with values then translates to the restriction that {emph"variables all are of positive type"}.

This rule has strong consequences: in <%mu(x,y),c%>, <%x%> and <%y%> must be of positive type, hence the two component of a pair must be values. In particular terms of the form <%(mu x,c,u)%>, like above, are no longer permissible. It is now well understood~{cite"Dyckhoff2006,Zeilberger2008,Munch2009,Curien2010"}, that this call-by-value restriction of sequent calculus is akin to focusing~{cite"Andreoli1992"}, though, on the details, it need not correspond too closely.

The classification of types is, hence, a strong restriction which we sum up with the following grammar, where <%A%> and <%B%> denote positive types and <%N%> and <%M%> denote negative types:
{displaymath begin syntax [
  syntax_line (`Other "<%A%>, <%B%>") Rules.Types.Polarised.positive;
  syntax_line (`Other "<%N%>, <%M%>") Rules.Types.Polarised.negative;
] end}
This grammar introduces two new dual connectives <%shiftn N%> and <%shiftp P%> -- both read ``shift'' -- to mediate between the two polarities.
(* This is not as interesting as I first thought
   Notice the two new types <%shiftn N%> and <%shiftp P%> which permit to embed positive and negative types into negative and positive types respectively. They both read ``shift''. Here again there was some amount of choice available: in Andreoli's treatment of focusing~{cite"Andreoli1992"}, every linear logic type is a valid type, the polarity only depends on the head connective and shifts are completely implicit (this approach is followed for {muname} in~{cite"Munch2009"}). In early {textsc"llp"} works~{citation}(* Olivier Laurent *), shifts were explicit, but conflated with the exponential connective <%!N%> was positive and <%?A%> was negative, it does not seem, however, easily amenable to the style of this article. In any case, the shift connectives have useful interpretations from a programming language perspective, which makes them interesting to study, hence their inclusion. *)
The shift connectives have reversed introduction rules, as <%shiftp P%> is introduced by the construction <%val v%> (read ``return'' <%v%>), and <%shiftn N%> by <%mu\(val x\),c%>, despite the former being negative and the latter positive. Indeed <%val v%> is a computation and <%mu\(val x\),c%> a value. Sequents for values are written <%Xi;Gamma|-_v t:A%>, this is purely cosmetic in this section, but the typing judgement of values and computations will be distinct in Section~{ref_ s_dep}.
{displaymath begin array [`C] [
  array_line ~sep:(`Mm 2.) [Rules.Typing.Fll.shiftn];
  array_line [ Rules.Typing.Fll.shiftp];
]end}
With the obvious reduction rule:
{displaymath (reduction Rules.Reduction.shift)}

As often, it is usually possible to define an alternative syntax to replace the {mu} pattern: <%shiftn N%> can alternatively be introduced by <%thunk t%> -- read ``thunk <%t%>'' -- defined as:
{displaymath "<%\(thunk t\) = mu\(val alpha\),<t|alpha> %>"}
The typing of which is given by:
{let open Infer in
 displaymath begin
   rule ~label:"definition"
     [rule ~label:negativeshift
         [rule ~label:(cutp"<%alpha%>")
             ["<%Xi;Gamma |- t:N%>"]
             "<%Xi;Gamma,alpha:N^~|-<t|alpha>%>"]
         "<%Xi;Gamma |-_v mu\(val alpha\),<t|alpha> : shiftn N%>"]
     "<%Xi;Gamma |-_v thunk t : shiftn N%>"
end}
And has as a reduction rule:
{displaymath "<%<thunk t | val u> ~~> <u|t>%>"}

{let sep = `Mm 2. in
 figurerules ~label:f_fll ~caption:"Polarised {muname}" [
   simple_block "Syntax" begin
     syntax [
       syntax_line `Term Rules.Syntax.(core@shift@multiplicative@additive@exponential);
       commands
     ]
   end;
   simple_block "Types" begin
     syntax [
       syntax_line (`Other "<%A%>, <%B%>") Rules.Types.Polarised.positive;
       syntax_line (`Other "<%N%>, <%M%>") Rules.Types.Polarised.negative;
     ]
   end;
   simple_block "Reduction" begin
     reduction Rules.Reduction.(core@shift@multiplicative@additive@exponential)
   end;
(*
   simple_block "Derived syntax" begin
     array [`L; symbsep $=$; `L] [
       array_line ["<%lambda x,t%>";"<%mu(x,alpha),<t|alpha>%>"];
       array_line ["<%t u%>"; "<%mu alpha, <t|(u,alpha)>%>"];
       array_line ["<%{1=t,2=u}%>"; "<%{mu(1.alpha),<t|alpha> , mu(2.alpha),<u|alpha>}%>"];
       array_line ["<%t.1%>"; "<%mu alpha,<t|1.alpha>%>"];
       array_line ["<%t.2%>"; "<%mu alpha,<t|2.alpha>%>"];
     ]
   end; *)
   block "Typing" [`C;`C] begin
     let open Rules.Typing.Fll in
         [
           block_line ~sep [ id ; cut ];
           block_line ~sep [ iddup ; mu ];
           block_line ~sep [ shiftn ; shiftp ; ];
           block_line ~sep [ pair ; copair ];
           block_line ~sep [ unit ; counit ];
           block_line ~sep [ iota1 ; case ];
           block_line ~sep [ iota2 ; empty];
           block_line ~sep [ zero ; emptycase ];
           block_line ~sep [ bang ; whynot ];
         ]
   end;
(*
   block "Derived typing rules" [`C;`C] begin
     let open Rules.Typing.Mall in
         [
           block_line ~sep [ lambda ; app ];
           block_line ~sep [ record ; pi1 ];
           block_line ~sep [ empty  ; pi2 ];
         ]
   end;
*)
 ]}

The other typing rules for polarised {muname} are given in Figure~{ref_ f_fll}. They are, actually, textually identical to the rules of linear {muname}, except that now <%A%> and <%B%> stand for positive types. Polarised {muname} is really only a matter of constraining the variables to have positive types.

The shift are not simple coercions between negative and positive types: they have a real computational significance. Indeed <%shiftp A%> is a bigger type than <%A%>: if <%A%> contains only values <%v%>, <%shiftp A%> contains any computation which {emph"evaluates to <%v%>"}. For instance, <%1%> only contains the value <%()%>, but <%shiftp 1%> contains computations like <%(lambda(),val ()) ()%>. In fact, polarised {muname} is a linear variant of Levy's call-by-push-value language~{cite"Levy2001"} ({textsc"cbpv"}. With <%shiftp A%> and <%shiftn N%> playing the role, respectively, of $F A$ and $U N$.

Like in {textsc"cbpv"}, computations can be chained, with the expression <%chain t x u%>, so that the value computed by <%t%> is bound to <%x%> in <%u%>, in a manner reminiscent of monadic composition.
{displaymath"<%chain t x u = mu alpha, < t | mu\(val x\), <u|alpha>>%>"}
with the same typing rule as in~{cite"Levy2001"} (up to linearity):
{let open Infer in
 displaymath begin
   rule ~label:"definition"
     [rule ~label:mu
         [rule ~label:cutrule
             ["<%Xi;Gamma|-t: shiftp A%>";
              rule ~label:negativeshift
                [rule ~label:(cutp"<%alpha%>")
                    ["<%Xi;Delta,x:A|- u : N%>"]
                    "<%Xi;Delta,alpha:N^~,x:A|- <u|alpha>%>"]
                "<%Xi;Delta,alpha:N^~|- mu\(val x\), <u|alpha>: shiftn A^~%>";]
             "<%Xi;Gamma,Delta,alpha:N^~|-< t | mu\(val x\), <u|alpha>>%>"]
         "<%Xi;Gamma,Delta|- mu alpha, < t | mu\(val x\), <u|alpha>> : N%>"]
     "<%Xi;Gamma,Delta|- chain t x u : N%>"
end}
Together with the reduction rule:
{displaymath"<%<chain \(val v\) x u | alpha> ~~> <subst[v,x] u| alpha>%>"}

Dually, the type <%shiftn N%> represents the type of suspended computations. A suspended computation differs from regular computation in that they can be stored in a value. Suspending a computation corresponds to an operation well-known to the functional programmer: building a closure. Indeed, a closure is nothing but packing a computation (typically in form of a code pointer) together with the environment necessary for the computation to be resumed later. That is, turning a computation into a value.

(* arnaud: ce paragraphe est trop bref, il faudra probablement y retourner *)
A feature shared by {textsc"cbpv"} and polarised {muname}, is that functions are computations <%A-oN%>. They are not made into closure unless they are suspended into the type <%shiftn(A-oN)%>. If closures are considered expensive to make, which they often are, this property can be useful as functions of multiple arguments <%A-oB-oC-oN%> do not need intermediary closures.

As a matter of fact, the Rust programming language~{citation_needed} has, for efficiency purposes, so-called {emph"stack closures"}, which are, in fact, not closures. Stack closures are functions which can be used only as argument of another function, and be called, but {emph"not"} be stored in a value. From the point of view of polarised {muname}, this would correspond to having variables of negative type, with restricted usage.

Suspended values, again inspired by {textsc"cbpv"}, can be turned back into computation with a <%force%> combinator:
{displaymath"<%force t = mu alpha, < t | val alpha>%>"}
Typed as
{let open Infer in
 displaymath begin
   rule ~label:"definition"
     [rule ~label:mu
         [rule ~label:cutrule
             ["<%Xi;Gamma|-_v t : shiftn N%>";
              rule ~label:positiveshift
                [rule ~label:idrule
                    []
                    "<%Xi;alpha:N^~ |-_v alpha:N^~%>"]
                "<%Xi;alpha:N^~ |- val alpha : shiftp N^~%>"]
             "<%Xi;Gamma,alpha:N^~ |- < t | val alpha >%>"]
         "<%Xi;Gamma |- mu alpha, < t | val alpha> : N%>"]
     "<%Xi; Gamma |- force t : N%>"
 end}
And with reduction rule:
{displaymath"<%<force \(thunk t\) | alpha> ~~> <t| alpha>%>"}

{subsection"Translations"}

Despite the call-by-value slant of polarised {muname}, both call-by-value and call-by-name {lambda}-calculus can be embedded in polarised {muname}. Again, all of the definitions are macros. For simplicity we will only give encoding of linear {lambda}-calculus, but the intuitionistic version is not very different. We use the definitions of <%lambda x,t%> and <%t u%> defined in Figure~{ref_ l_mall}, like the other connectives they have only changed inasmuch as the polarisation of the operands of the arrow type: the arrow <%A-oN = A^~`&N%> has positive domain and negative codomain. (* arnaud: ce dernier passage pourrait ^etre racont'e quand je parle de cl^otures plus haut *)

Call-by-name {lambda}-calculus is obtained by interpreting all type as being negative. As a consequence, all variables in the context must be shifted which modifies the variable rule, and the arrow is encoded as <%shiftn N -o M%>:
{let sep = `Mm 3. in
 let open Infer in
 let idenc =
   rule ~label:"force"
     [rule ~label:idrule [] "<%;Gamma,x:shiftn N |- x:shiftn N%>"]
     "<%;Gamma,x:shiftn N|-force x : N%>"
 in
 let appenc =
   rule ~label:apprule
     ["<%;Gamma|-t : shiftn N -o M%>";
      rule ~label:negativeshift
        ["<%;Delta|-u:N%>"]
        "<%;Delta |- thunk u : shiftn N%>"]
     "<%;Gamma,Delta|- t \(thunk u\) : M%>"
 in
 let absenc =
   rule ~label:lambda
     ["<%;Gamma,x:shiftn N |- t : M%>"]
     "<%;Gamma|- lambda x, t : shiftn N -o M%>"
 in
 displaymath begin array [`C] [
   array_line ~sep [idenc];
   array_line ~sep [appenc];
   array_line [absenc];
 ]end}

In call-by-name {lambda}-calculus, the arguments of functions are suspended so that their computation happens at use point: when the variables are used and forced. This translation, which is mostly forced by the choice that all types are interpreted as negative, happens to correspond closely to simple implementations, for instance Krivine's abstract machine~{citation_needed}.

Dually, in call-by-name {lambda}-calculus all of the types are interpreted as positive. Since a {lambda}-term is a computation, not a value, the type of the terms -- rather than the hypotheses as in call by name -- must be shifted. Also, the encoding of functions is a little more involved: <%shiftn(A-oshiftp B)%>. Again, this translation follows straightforwardly from the choice that every type is positive.
{let sep = `Mm 3. in
 let open Infer in
 let idenc =
   rule ~label:positiveshift
     [rule ~label:idrule [] "<%;Gamma,x:A|-x:A%>"]
     "<%;Gamma,x:A|-val x : shiftp A%>"
 in
 let appenc =
   rule ~label:"chain"
     ["<%;Delta|-u:shiftp A%>";
      rule ~label:"chain"
        ["<%;Gamma|-t : shiftp shiftn (A -o shiftp B)%>";
         rule ~label:"app"
            [rule ~label:"force"
                [rule ~label:idrule [] "<%;f:shiftn (A-oshiftp B)|- f: shiftn (A-oshiftp B)%>"]
                "<%;f:shiftn (A-oshiftp B)|- force f: A-oshiftp B%>";
             rule ~label:idrule
               []
               "<%;x:A |- x:A%>"]
            "<%;x:A,f:shiftn (A-oshiftp B)|- force f x : shiftp B%>"]
        "<%;Gamma,x:A|-chain t f \(force f x\) : shiftp B%>";]
     "<%;Gamma,Delta|- chain u x \(chain t f \(force f x\)\) : shiftp B%>"
 in
 let absenc =
   rule ~label:positiveshift
     [rule ~label:"thunk"
         [rule ~label:lambda
             ["<%;Gamma,x:A |- t : shiftp B%>"]
             "<%;Gamma|- lambda x, t : A -o shiftp B%>"]
         "<%;Gamma|- thunk lambda x, t : shiftn (A -o shiftp B)%>"]
     "<%;Gamma|- val thunk lambda x, t : shiftp shiftn (A -o shiftp B)%>"
 in
 displaymath begin array [`C] [
   array_line ~sep [idenc];
   array_line ~sep [appenc];
   array_line [absenc];
 ]end}

As in any call-by-value calculus, there is a non-canonical choice in the order of evaluation. We observe it in the translation of application: we chose to evaluate the argument before the function, but the reverse works just as well and behaves differently in presence of effects.

{rule_ (`Mm 3.) (`Mm 3.)}

<%< chain (chain t x u) y v | alpha >%>

<%< chain t x u | mu\(val y\), <v|alpha> >%>

<%< t | mu\(val x\), < u | mu\(val y\), <v|alpha> >>%>

{rule_ (`Mm 2.) (`Mm 2.)}

<%< chain t x \(chain u y v\) | alpha >%>

<%< t | mu\(val x\), < chain u y v | alpha >>%>

<%< t | mu\(val x\), < u | mu\(val y\), < v | alpha >>>%>

{rule_ (`Mm 2.) (`Mm 2.)}

<%< chain v x \(chain (chain u y \(chain t f \(force f y\)\)) g \(force g x\)\) | alpha >%>

<%< chain v x \(chain u y \(chain t f \(chain (force f y) g \(force g x\)\)\)\) | alpha>%>

{rule_ (`Mm 2.) (`Mm 2.)}

<% < chain (force (thunk lambda z, val thunk lambda w, t ) y) g \(force g x\) | alpha > %>

<% < chain ((lambda z, val thunk lambda w, t) y) g \(force g x\) | alpha > %>

<% < chain (val thunk lambda w, subst [y,z] t) g \(force g x\) | alpha > %>

<% < force (thunk lambda w, subst [y,z] t) x | alpha > %>

<% < (lambda w, subst [y,z] t) x | alpha > %>

<% < subst [y,z;x,w] t | alpha > %>

{rule_ (`Mm 2.) (`Mm 2.)}

In a similar fashion to {lambda}-calculus, linear {muname} has two encodings into polarised {muname}, one where types are interpreted as negative and the other as positive, with very different computational behaviour.

When interpreting types of linear {muname} as negative types, the type <%N<*>M%> of pairs is interpreted as <%shiftp(shiftn N <*> shiftn M)%>. And the pair constructor <%(u,v)%> as <%val (thunk u, thunk v)%>. The dual type <%N`&M%> is interpreted as <%\(shiftp shiftn N\)`&\(shiftp shiftn M\)%> and the decomposition <%mu(x,y),c%> is also unchanged. Like in call-by-name {lambda}-calculus, variable in the context have their type shifted, and the variables (whether duplicable or linear) are interpreted as <%force x%>.

The cut rule is interesting

In other word, decomposition forces only the head constructor which is necessary to continue the computation. This is the same behaviour as Haskell (except that Haskell is call-by-need, hence must share suspended computations rather than duplicating them). This translation deserves to be called {emph"call by name"}.

The dual translation where the types are interpreted as positive works like a call-by-value language. The pair type <%A<*>B%> is simply interpreted as <%A<*>B%>, but like in call-by-value {lambda}-calculus, the translation of a linear {muname} term need to be a computation, hence the type of terms is shifted. So the pair <%(u,v)%> is interpreted as <%chain v x \(chain u y (y,x)\)%> of type <%shiftp (A<*>B)%> (again, the order of evaluation is non-canonical).

The dual type <%A`&B%> is interpreted as <%shiftn(shiftp A `& shiftp B)%>. Decomposition <%mu(x,y),c%> is implemented as <%val thunk mu(x,y),c%>of type <%shiftp shiftn(shiftp A `& shiftp B)%>.

{rule_ (`Mm 2.) (`Mm 2.)}

"
