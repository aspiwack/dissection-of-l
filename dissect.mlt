(* -*- compile-command: "ocamlbuild -classic-display dissect.pdf && evince _build/dissect.pdf" -*- *)

##verbatim '%' = MuPlugin.mumode

open Prelude


let symbsep s = `Sep ${quad}{s}{quad}$
let syntax_line k ?(extend=false) l =
  let k = match k with
    | `Term -> "<%t%>, <%u%>"
    | `Command -> "<%c%>"
  in
  let l = if extend then ldots::l else l in
  array_line [ k ; concat_with_sep l mid ]
let commands = syntax_line `Command ["<%<t|u>%>"]
let syntax l = array [`L;symbsep grammardef; `L] l
let reduction l = array [`L; symbsep leadsto; `L] l
(* arnaud: note, la fonte pour sans serif (textsf) a l'air de n'être
   pas à la même taille que celle de la fonte romane… ça n'est
   pas très beau. *)

(*** doc ***)
let abstract = "There will be an abstract some day."

let intro = "{section' "Foreword"}

In this article I will discuss typing of a calculus -- or, to be
fair, a family of calculus -- I call {mu}. It originates from a
paper by Herbelin \& Curien~{citation_needed}, where it was
called ${bar lambda}{mu}{tilde mu}$-calculus. It has since been
often called simply ${mu}{tilde mu}$, or system L
syntax~{citation_needed}. The latter name comes from
proof-theoretical investigations, this article has more a programming
language feel, and we will not see a {tilde mu}. Hence just {mu}.

The {foreign "tour de force"} of {mu}, in my opinion, is to provide
a syntax for classical sequent calculus proofs in which, like {lambda}-calculus
for natural deduction, contraction and weakening are done through
variables: a bound variable which isn't used is weakened, if it is
used twice or more it is contracted. This is, I would argue, why
it makes a good foundation for a programming language.

To me at least, the appeal of sequent calculus is hard to resist. It
has a more symmetric structure than natural deduction, and proof search
is more naturally expressed in it. Importantly for this article, Lengrand
has shown~{citation_needed} that proof search is expressed naturally
in a dependently typed (intuitionist) sequent calculus.

The object of this paper, is to study {mu} as a programming language whose
typing rules correspond to linear sequent calculus. And then to add dependent
types to the mix. The main motivation is to use this calculus as a stepping
stone to understand mathematics in presence of computational effects (as
linear logic can be used, to some extent, to model effects~{citation_needed}).
I also hope to use dependent linear {mu} as a new lense through which
usual dependently typed language could be further analysed.
The choice of linear logic rather than some flavour of intuitionist linear
logic might be a matter of taste, I tend to favour symmetry when I can; it
was originally a challenge as well, as dependent types are somewhat antagonistic
to the kind of commutation sequent calculus allow. In retrospect, though,
it may very well be that linear dependent types are easier -- at least using
{mu} as a framework -- than intuitionist linear dependent types.
"

let coremu = "{section "Core {mu}"}

Stripped down to its bare minimum, {mu} appears as a very simple calculus whose
syntax is made of two kinds of objects, terms (<%t%>, <%u%>, <%v%>) and commands
(<%c%>)
{displaymath begin syntax [
  syntax_line `Term Rules.Syntax.core;
  commands
] end}
Together with reduction rules
{displaymath begin reduction [
  Rules.Reduction.mu;
  array_line [ "<%<mu x,c|t>%>" ; "<%subst [t,x] c%>" ];
] end}
The intent being that the vertical bar be read as commutative. We shall using
as such from now on.

Given a command <%c%>, the term <%mu x, c%> can be thought as ``let <%x%> be
the current continuation, do <%c%>''. Conversely, for two terms, <%t%> and <%u%>
<%<t|u>%> runs <%t%> with continuation <%u%> (or symmetrically, <%u%> with
continuation <%t%>) it is read ``<%t%> against <%u%>''.
Terms reduce to a value, whereas command just compute -- they are played only
for there effects. Though it is possible to imagine otherwise, and consider
{textsc"io"} of sorts, the only effects available to a computation in pure {mu}
is returning to a continuation.

The reduction rules look quite similar to {beta}-reduction,
however this core calculus does not have nearly the power of {lambda}-calculus.
Indeed the fact that there are two kinds of object is crucial here: from a
functional programming perspective, it is like if the only construct was
{textsf"let{ldots}in"}. Contrary to {lambda}-calculus we have practically no
computation power without additional constructs.

Nonetheless, we can already observe undesirable behaviours. For instance it is easy to
cook up a non-terminating command <%<mu x,<x|x> | mu x,<x|x>>%>.
Much worse: any two commands <%c_1%> and <%c_2%> are redux of a common command
<%<mu alpha, c_1 | mu alpha, c_2>%> where <%alpha%> is fresh. (*arnaud: essayer de regarder les conflits contraction/contraction et weakening/contraction*)

{subsection "Typing as classical sequent calculus"}

The original typing rules~{citation_needed} for {mu} corresponded closely to classical
sequent calculus. We shall present, here, a one-sided version of them. Core mu does not
have any connective, however as is necessary in a one-sided sequent calculus, we shall
assume that every formula <%A%> has a dual <%A^~%>, and that <%A^~^~%> is <%A%> itself.

There are two kinds of sequents, one for each kind of objects: terms are typed with
sequent of the form
{displaymath "<%Gamma|-t:A%>"}
and commands with sequents
{displaymath "<%Gamma|-c%>"}

Readers familiar with one-sided sequent calculi might wonder why we used this particular
form for sequents. It was chosen mostly for its resemblance to natural deduction sequents,
more familiar in the realm of programming languages; also it allows variables to appear
with the same type in terms and in the context.

The three typing rules for classical core {mu} are the identity rule, giving their type
to variables
{displaymath Rules.Typing.id}
the {mu} rule, for {mu} abstractions
{displaymath Rules.Typing.mu}
and the cut rule giving their types to interactions
{displaymath Rules.Typing.cut}
where the context is considered up to commutation of the comma.

What should be taken away from these rules is that the identity and cut rules are sufficient
to make weakening and contraction admissible. It is also the case that reduction is terminating,
as terms like the aforementioned <%<mu x,<x|x> | mu x,<x|x>>%> cannot be typed. On the other hand,
non-confluence is still as acute as the following derivation demonstrates:
{displaymath begin
  Infer.rule [
       Infer.rule [Infer.rule [] "<%Gamma,alpha:A^~|- c_1%>"] "<%Gamma|-mu alpha,c_1 : A%>";
       Infer.rule [Infer.rule [] "<%Gamma,beta:A|- c_2%>"] "<%Gamma|-mu beta,c_2 : A^~%>"]
  "<%Gamma|-<mu alpha,c_1|mu beta, c_2>%>"
end}
Hence, by the weakening property, if <%c_1%> and <%c_2%> are both typable in <%Gamma%>, then they are
redux of a common typable term in <%Gamma%>. This is, in fact, nothing more than the classical
weakening-weakening critical pair of cut elimination.

{subsection "Typing as linear sequent calculus"}
To address the confluence issue, we move from a classical sequent calculus. In the case of core
{mu} this simply requires simple modifications of the identity rule
{displaymath (Infer.rule ~label:idrule [] "<%x:A|-x:A%>")}
and cut rule
{displaymath (Infer.rule ~label:cutrule ["<%Gamma|-t:A%>";"<%Delta|-u:A^~%>"] "<%Gamma,Delta|-<t|u>%>")}
to prevent weakening and contraction to happen. The {mu} rules stays as above.

Would we to limit the exchange of formul{ae} in the context, we could play with the {mu} rule. We shall, however,
keep reading the comma as commutative.
"

let llmu = "{section "Linear {mu}"}
As mentioned in the previous section, core {mu} does not have all that much computing abilities.
This has much to do with the fact that its typing rules don't involve any connectives.
In this section we shall extend {mu} constructs to reflect the whole range of linear logic
connectives.

{subsection "Multiplicative fragment"}
The multiplicative connectives <%A<*>B%> and <%A`&B%> are reflected in the syntax as two
term constructors
{displaymath begin syntax [
  syntax_line `Term ~extend:true Rules.Syntax.([ pair ; copair ]);
] end}
a pairing construct, and a pair elimination construct whose reduction rule is
{displaymath begin reduction [
  Rules.Reduction.pair
] end}
In a pattern that will repeat itself throughout this article, the tensor product
is a {emph"positive"} construction, and its proofs are, hence, built out of terms, and the
par is a {emph"negative"} construction and its proofs are built out of command, and have
a pattern-matching feel.

The corresponding typing rules are fairly straightforward
{displaymath Rules.Typing.pair}
{displaymath Rules.Typing.copair}

Using these rules, we can encode the somewhat more familiar constructs of (linear) {lambda}-calculus. Writing,
as usual, <%A-oB%> for <%A^~`&B%> we get abstraction
{displaymath (Infer.rule ~label:parr [Infer.rule ~label:cutrule ["<%Gamma,x:A|-t:B%>";Infer.rule ~label:idrule [] "<%alpha:B^~|-alpha:B^~%>"]
                                           "<%Gamma,x:A,alpha:B^~|-<t|alpha>%>"]
                 "<%Gamma|-mu(x,alpha),<t|alpha>:A-oB%>")}
and application
{displaymath (Infer.rule ~label:mu [Infer.rule ~label:cutrule ["<%Gamma|-t:A-oB%>";Infer.rule ~label:tensor ["<%Delta|-u:A%>";Infer.rule ~label:idrule [] "<%alpha:B^~|-alpha:B^~%>"] "<%Delta,alpha:B^~|-(u,alpha):A<*>B^~%>"] "<%Gamma,Delta,alpha:B^~|- <t|(u,alpha)>%>"] "<%Gamma,Delta|-mu alpha, <t|(u,alpha)> : B%>")}

We shall henceforth write <%lambda x,t%> for <%mu(x,alpha),<t|alpha>%> and <%t u%> for <%mu alpha, <t|(u,alpha)>%>.
Apart from systematically deriving them from their desired typing rules, as above, the best way to understand these two derived construct is via abstract machines. Indeed, reading alpha as {emph"the stack"}, the application reads
``play <%t%> against the stack augmented by <%u%>'', this is the {emph"push"} instruction of abstract machines.
Abstraction, dually, reads as ``let <%x%> be the top of the stack, play <%t%> against the rest of the stack'',
that is, the {emph"grab"} instruction of virtual machines.

The correspondence with abstract machines is no coincidence, and we shall encounter it again. It can be
viewed as a consequence of the fact that, through its core construction, {mu} internalises the notion of
stack. In fact, when writing an abstract machine for {mu} there is no need of an explicit stack, everything
stack-like is taken care of by the multiplicative constructs.

(* arnaud: On pourrait penser à parler un peu des deux vues, quand A<*>B est le terme et A`&B le contexte
   et vice-versa *)

{subsection "Additive fragment"}

Additive type constructors include <%A<+>B%> and <%A&B%>, where the former is positive, hence built out
of terms and the latter negative and built out of commands. They are used to implement case analysis,
with a term of type <%A<+>B%> is pattern-matched by the term of type <%A^~&B^~%> it is played against.
Dually, a term of type <%A&B%> can be seen as a {emph"record"} and a term of type <%A^~<+>B^~%> provides
the projection (together with its continuation).

The syntax of their terms is as follows
{displaymath begin syntax [
  syntax_line `Term ~extend:true Rules.Syntax.([iota1;iota2;case])
] end}
and comes with the reduction rules
{displaymath begin reduction Rules.Reduction.([ iota1 ; iota2 ]) end}
{let l_mall = label ~name:\"l:mall\" () in
"The typing rules are fairly straightforward. The whole multiplicative and additive fragment can
be found in Figure {ref_ l_mall}.

As for the multiplicative fragment, we can define useful derived term constructors. To better
encode records, we write <%{1=t,2=u}%> for <%{mu(1.alpha),<t|alpha> , mu(2.alpha),<u|alpha>}%>
(with <%alpha%> fresh). The projections are <%t.1%> and <%t.2%>, and stand for
<%mu alpha,<t|1.alpha>%> and <%mu alpha,<t|2.alpha>%>, respectively.

{figure ~label:l_mall ~caption:"Multiplicative and additive fragment"
    begin
      let title_line x = array_line [x] in
      array [`C] [
        title_line "Syntax";
        array_line [ syntax [
          syntax_line `Term Rules.Syntax.(core@multiplicative@additive);
          commands
          ];
        ];
        title_line "Reduction";
        array_line [ reduction Rules.Reduction.(core@multiplicative@additive)
        ];
        title_line "Derived syntax";
        array_line [ array [`L; symbsep $=$; `L] [
          array_line ["<%lambda x,t%>";"<%mu(x,alpha),<t|alpha>%>"];
          array_line ["<%t u%>"; "<%mu alpha, <t|(alpha,u)>%>"];
          array_line ["<%{1=t,2=u}%>"; "<%{mu(1.alpha),<t|alpha> , mu(2.alpha),<u|alpha>}%>"];
          array_line ["<%t.1%>"; "<%mu alpha,<t|1.alpha>%>"];
          array_line ["<%t.2%>"; "<%mu alpha,<t|2.alpha>%>"];
          ]
        ];
        title_line "Typing";
        array_line [
          let open Rules.Typing in
              array [ `C ; `C ] [
                array_line [ mu ; empty ];
                array_line [ id ; cut ];
                array_line [ pair ; copair ];
              ]
        ]
      ]
    end}

"}
"

let d = concat [
  intro;
  coremu;
  llmu;
]

let _test = "{Infer.rule ~label:(mathrm $Dummy$) ["<%<mu x, c|y>%>"] "<%A<*>B%>"}"
      
(*** boilerplate ***)

let title = "Dissecting {mu}"
let authors = [
  { name = "Arnaud Spiwack";
    email = Some "arnaud@spiwack.net";
    address = "Inria -- {textsc "pps"} -- Université Paris Diderot, France"
  };
]

let keywords = [
  "Sequent calculus";
  "Dependent types";
  "Linear logic";
  "Focusing";
(*  "μμ̃"; Confuses latex *)
]

let acmclass = [
  "F.3.1"; (* (un peu douteux) Specifying, and verifying and reasoning about programs http://dl.acm.org/ccs.cfm?part=author&coll=DL&dl=ACM&row=F.3.1&idx=6&idx2=F.3.1&idx3=3&query=Subject%3A%22Logics%20of%20programs%22&CFID=83889239&CFTOKEN=84492988 *)
  "F.3.3"; (* (moins douteux) Studies of program constructs http://dl.acm.org/ccs.cfm?part=author&coll=DL&dl=ACM&row=F.3.3&idx=6&idx2=F.3.3&idx3=5&query=Subject%3A%22Type%20structure%22&CFID=83889239&CFTOKEN=84492988 *)
]

let packages = [
  "inputenc" , "utf8" ;
  "fontenc" , "T1" ;
  "textcomp", "";
  "microtype" , "" ;
]

let prelude = concat_with_sep [] par

let file = \"dissect.tex\"

let _ = emit ~file (document
		             ~title
			     ~authors
                             ~keywords
                             ~acmclass
			     ~prelude
			     ~packages
                             ~abstract
			     d)
