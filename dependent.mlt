##verbatim '%' = MuPlugin.mumode
##verbatim '@' = Ocamlmode.ocamlmode

open Prelude
open Extra




let d = "{section"Dependent types" ~label:s_dep}

Polarised {muname}, with its type-based distinction of values and computations, gives an answer to the question of what it means for type to have effects in them: the answer is, they should not exist. If we see the type <%PI x:A, N%> as a generalisation of the type <%A-oN%>, it is clear that <%x%> only stands for values.

The obvious limitation is that even pure computation are ostensibly forbidden in types, preventing proofs by computation which are quite popular in modern dependent-type-theory-based proof assistants~{cite"Boutin1997"}. Another, somewhat separate, issue which is not addressed in this last section is that of the computation {emph"of"} types (aka {emph"strong elimintation"}), which would be necessary to prove, for instance, the equivalence of <%A<+>B%> and <%SIGMA x:1<+>1, <x|{ mu(1.()), A , mu(2.()), B } >%>. The latter will not even be a valid type.

Despite these limitation, this modest proposal for a dependently typed linear logic is already a fairly expressive logic which includes dependent elimination -- as described in Section~{ref_ ss_depelim}.

{subsection"Weak dependent types"}

A first approach to extend linear {muname} or polarised {muname} with dependent types is to leverage the remark that the duplicable context behaves like a natural deduction context. We could therefore define a dependent product <%PI x:A,N%> like in natural deduction. This dependent product would generalise <%!A-oN%> and we would retain a separate, non-dependent, linear arrow <%A-oN%>. Such a system would be along the lines of linear {textsc"lf"}~{cite"Cervesato1996"}, except in sequent calculus form rather than a natural deduction.

There are no particular difficulty with this approach, but it has severe limitations. The most important limitation is that such a system cannot be extended to dependent elimination. The system we propose in this section has a dependent product which generalises the linear arrow. In Section~{ref_ ss_depelim}, we enrich it with dependent elimination.

A key point of our presentation of {muname} so far, is that <%mu alpha,<t|alpha>%> is essentially the same as just <%t%>, this underlies, in particular, our encoding of pattern-matching, and of linear {lambda}-calculus. This is problematic if types depend on linear variables. Indeed, if <%t%> has type <%N%>, which depend on some linear variable <%x%>, we need <%alpha%> to have type <%N^~%> which also depends on <%x%>. But variables have to be split between <%t%> and <%alpha%> so <%x%> can only go on one side of the cut.

This is where the polarised discipline helps: as variables represent only values, we can restrict type to contain values which are harmless in that they cannot perform effects by themselves. So, it is innocuous to allow variable duplication in types. In this proposal, it is manifested by a third context -- usually denoted <%Theta%> -- in the typing judgement of value, which represents variables accessible from the type, but not from the value.

This new typing context affects principally the identity and cut rules. Indeed another way one can think about the typing context is that it allows variables to have any type.
{displaymath begin array [`C;`Sep(qquad^^qquad);`C] [
  array_line [ Rules.Typing.Dll0.id ; Rules.Typing.Dll0.cut ];
 ]end}
In the cut rule, the variables which are necessary to make sense of the types in <%Gamma%> and <%A%> but occur in the computation <%u%> are kept in the typing context of the value <%t%>. In the identity rule, the duplicable context and the typing context are joined: types do not make a difference between linear and duplicable variables.

The full system is given in Figure~{ref_ f_wdll}. It makes the simplifying hypothesis that the type of duplicable variables does not depend on linear variables. When we write $"<%Gamma%>","<%Delta%>"$, it is implied that types in <%Delta%> may depend on variables of <%Gamma%> but types of <%Gamma%> may not depend on variables of <%Delta%>. Also, all context which appear in the premise of a typing rule is supposed to make sense, hence in the cut and tensor rule, it is understood that <%Gamma%> and <%Delta%> do not depend on each other, and in the introduction rule for <%?A^~%>, the context <%Gamma%> does not depend on <%x%>. These independence constraints are omitted for the sake of readability. Apart from the dependencies between bindings in the context, the context is not assumed to have a particular ordering. In particular, the context does not have a linear structure, in contrast with common practice in dependently typed natural deduction. Notice that we use a dependent product <%PI x:A,N%> which generalises the linear arrow, rather than a more symmetric generalisation of <%N`&M%>, this is simply by lack of a notation for the latter. We assume that duality commutes with conversion{footnote"There is no way, in Figure {ref_ f_wdll}, to actually have values in types. So of course, substitution~--~which is the identity~--~commutes with dualisation. This assumption should rather be seen as a constraint on extensions of the system."}.
{let sep = `Mm 2. in
 
 figurerules ~label:f_wdll ~caption:"Weak dependent {muname}" [
   (* simple_block "Syntax" begin *)
   (*   syntax [ *)
   (*     syntax_line `Term Rules.Syntax.(core@shift@multiplicative@additive@exponential); *)
   (*     commands *)
   (*   ] *)
   (* end; *)
   simple_block "Reduction" begin
     reduction Rules.Reduction.(core@shift@multiplicative@additive@exponential)
   end;
(*
   simple_block "Derived syntax" begin
     array [`L; symbsep $=$; `L] [
       array_line ["<%lambda x,t%>";"<%mu(x,alpha),<t|alpha>%>"];
       array_line ["<%t u%>"; "<%mu alpha, <t|(u,alpha)>%>"];
       array_line ["<%{1=t,2=u}%>"; "<%{mu(1.alpha),<t|alpha> , mu(2.alpha),<u|alpha>}%>"];
       array_line ["<%t.1%>"; "<%mu alpha,<t|1.alpha>%>"];
       array_line ["<%t.2%>"; "<%mu alpha,<t|2.alpha>%>"];
     ]
   end; *)
   block "Typing" [`C;`C] begin
     let open Rules.Typing.Dll0 in
         [
           block_line ~sep [ id ; cut ];
           block_line ~sep [ iddup ; mu ];
           block_line ~sep [ shiftn ; shiftp ; ];
           block_line ~sep ~sync:false [ pair ; empty ];
           block_line ~sep ~sync:false [ empty ; copair ];
           block_line ~sep [ unit ; counit ];
           block_line ~sep [ iota1 ; case ];
           block_line ~sep [ iota2 ; empty];
           block_line ~sep [ zero ; emptycase ];
           block_line ~sep [ bang ; whynot ];
         ]
   end;
   block "Types" [`C;`C;`C;`C] begin
     let open Rules.Typing.Dtypes in
     [
           block_line ~sep [ one ; bot ; tensor ; par ; ];
           block_line ~sep [ zero ; top ; plus ; witha ; ];
           block_line ~sep [ shiftn ; shiftp ; bang ; whynot ];
     ]
   end
(*
   block "Derived typing rules" [`C;`C] begin
     let open Rules.Typing.Mall in
         [
           block_line ~sep [ lambda ; app ];
           block_line ~sep [ record ; pi1 ];
           block_line ~sep [ empty  ; pi2 ];
         ]
   end;
*)
 ]}

As a consequence of this presentation, values do not reference the linear variables which occur in their types. This is a form of uniformity which values have to conform to: in the types of values, term variables behave a little like the type variables of the Hindley-Milner type system.

Maybe surprisingly, as the only substitution occur in the premises of the tensor rule, the typing rules, in weak dependent {muname}, of linear {lambda}-abstraction and application correspond to standard rules for dependently typed {lambda}-calculus -- except linear.

Linear {lambda} abstraction <%lambda x,t%> which is defined, as before, as <%mu(x,alpha),<t|alpha>%> demonstrates the essential use of the typing context:
{let open Infer in displaymath begin
  rule ~label:parr
    [rule ~label:cutrule
        ["<%Xi;Gamma,x:A|-t:N%>" ;
         rule ~label:idrule
           ["<%Xi,Gamma,x:A|-N^~:Type%>"]
           "<%Xi; Gamma,x:A; alpha:N^~|-_v alpha : N^~%>"]
        "<%Xi;Gamma,x:A,alpha:N^~|- <t|alpha>%>"]
    "<%Xi;Gamma |- mu(x,alpha),<t|alpha> : PI x:A,N%>"
end}
The typing derivation of the application <%t u = mu alpha,<t|(u,alpha)>%> indeed performs a substitution in the body of <%PI x:A,N%>. The well-formedness conditions of types are omitted for brevity:
{let open Infer in displaymath begin
  rule ~label:mu
    [rule ~label:cutrule
        ["<%Xi;Gamma|-t:PI x:A,N%>" ; rule ~label:tensor ["<%Xi;Gamma;Delta|-_v u:A%>";rule ~label:idrule [] "<%Xi;Gamma;alpha:subst [u,x] N^~ |-_v alpha : subst [u,x] N^~%>"] "<%Xi;Gamma;Delta,alpha:subst [u,x] N^~|-_v (u,alpha):SIGMA x:A,N^~%>"]
        "<%Xi;Gamma,Delta,alpha:subst [u,x] N^~|- <t|(u,alpha)>%>"]
    "<%Xi;Gamma,Delta |- mu alpha, <t|(u,alpha)> : subst [u,x] N%>"
end}

Weak dependent {muname} is not very expressive, nonetheless the various implementations of {textsc"lf"} have demonstrated that this weak kind of dependent types can already be quite useful~{cite"Pfenning1991,Avron1992,Harper1993,Pfenning1999"}. It is also pleasant that we could derive a natural definition for a dependently typed {emph"linear"} {lambda}-calculus from design choices which are largely technical, and were not meant to force this definition.

{subsection"Dependent elimination"~label:ss_depelim}

If weak dependent {muname} can encode dependently typed linear {lambda}-calculus, as it happens, this does not extend to regular {lambda}-calculus, as we shall demonstrate momentarily. This is because it lacks so-called dependent elimination. Going back to the always quite representative multiplicative fragment, let us consider the following statement, in {textsc"ml"}-like syntax:
{displaymath"<@let (x,y) = u in v@>"}
or in the syntax of {muname}:
{displaymath"<%mu alpha, < u | mu(x,y),<v|alpha> >%>"}
In weak dependent {muname}, the type of <%v%> cannot depend on <%x%> or <%y%> as it has the dual type of <%alpha%>'s, but <%alpha%> is not in the scope of <%x%> and <%y%>.

Concretely, let us suppose that we have a positive type <%u=v%> whose formation rule is given by:
{displaymath begin
  Infer.rule
    ["<%Xi;Gamma|-u:A%>";"<%Xi;Gamma|-v:A%>"]
    "<%Xi,Gamma|-u=v:Type%>"
end}
And introduction rule
{displaymath begin
  Infer.rule
    ["<%Xi,Theta|-u=u:Type%>"]
    "<%Xi;Theta;Gamma|-_v refl:u=u%>"
end}
We will not need the dual type.

With such a type it would be desirable, but is not possible in weak dependent {muname}, to prove the statement
{displaymath"<%PI x:A<*>B, shiftp SIGMA y:A, SIGMA z:B, x=(y,z)%>"}
That every value in <%A<*>B%> is a pair.

Dependent elimination allows, in <@let (x,y) = u in v@> to link <@u@> with <@(x,y)@> in the type of <@v@>. Dependent elimination comes in two main brands: Paulin's style~{cite"Paulin-Mohring1993"}, as used by Coq, and Coquand's style~{cite"Coquand1992"}, as used by Agda. In Paulin elimination, the type of <@v@> may contain references to <@(x,y)@> which are transformed into occurrences of <@u@> in the type of the whole term. Coquand's elimination does the same to the whole typing context. Since, in {muname}, elimination is introduced over commands, which do not have a distinguished type, dependent elimination in dependent {muname} will resemble Coquand elimination most.

Looking closely at the representation of elimination in {muname}
{displaymath"<%mu alpha, < u | mu(x,y),<v|alpha> >%>"}
we can observe that dependent elimination must be split in two parts -- in contrast with natural deduction where elimination is a single operation. First, in <%mu(x,y), <v|alpha>%>, the types of <%v%> and <%alpha%> may depend on <%(x,y)%> and this dependency must be hidden as <%x%> and <%y%> are going out of scope. And in a second time -- when cutting with <%u%> -- <%u%> must be linked into the type.

This leads to the idea of introducing a distinguished variable, which we write <%cv%> which stands for the value against which the current computation will be cut{footnote"Credit where credit is due: this idea was originally formulated by Hugo Herbelin in an unpublished draft. The context was an intuitionistic dependent type theory in sequent calculus form."}. Notice that by definition, since variables only stand for values and values are cut against computation, the {emph"cut variable"} <%cv%> can only appear in the typing judgement of computations, not of values, nor of commands.

In the typing judgements of computations, we use names such as <%N_cv%> or <%Gamma_cv%> as reminders that the type or context can contain the cut variable. Here is the cut rule:
{displaymath Rules.Typing.Dll1.cut}
Notice how, since the duplicable context is shared between the value and the computation, it does not make sense for it to contain the cut variable. The cut rule eliminates the cut variable by replacing it with the value <%t%> as the semantics of the cut variable mandates.

The cut variable is introduced by the {mu}-binders, notably in the introduction rule for <%N`&M%>:
{displaymath Rules.Typing.Dll1.copair}
So, indeed, <%c%> is typed as if the hypothetical cut value was <%(x,y)%>. In this rule <%PI x:A, B^~%> does not mention the cut variable. Just as in the cut rule, the type <%A^~%> does not mention the cut variable. Types of computation are duals of types of values which do not have the cut variable. All of the mentions of type variable are in the context, which is not a problem since the current continuation can be hosted there. Indeed here is the rule for dependent elimination of pairs:
{let open Infer in
displaymath begin
  rule ~label:parr
    [rule ~label:cutrule
        ["<%Xi;Gamma,x:A,y:B|- v : \(subst [(x,y),cv] N_cv\)%>";
         rule ~label:idrule
           [small "<%Xi,Gamma,x:A,y:B|-\(subst [(x,y),cv] N_cv\)^~ : Type%>"]
           (small "<%Xi;Gamma,x:A,y:B;alpha:\(subst [(x,y),cv] N_cv\)^~|-_v alpha : \(subst [(x,y),cv] N_cv\)^~%>")]
        "<%Xi;Gamma,x:A,y:B,alpha:\(subst [(x,y),cv] N_cv\)^~|- < v | alpha >%>"]
    "<%Xi;Gamma,alpha:\(N_cv\)^~ |- mu(x,y), < v | alpha > : A^~`& B^~%>"
end}
Which can be further combined with a value <%u%> to obtain a rule akin to dependent elimination in natural deduction (omitting the type well-formedness constraint):
{let open Infer in
 displaymath begin
   rule ~label:mu
     [rule ~label:cutrule
         ["<%Xi;Gamma;Delta|-_v u : A<*>B%>";
          derived
            ["<%Xi;Gamma,x:A,y:B|- v : subst [(x,y),cv] \(N_cv\)%>"]
            "<%Xi;Gamma,alpha:\(N_cv\)^~|- mu(x,y), < v | alpha > : A^~`& B^~%>"]
         "<%Xi;Gamma,Delta,alpha:subst [u,cv] \(N_cv\)^~|- < u | mu(x,y), < v | alpha > > %>"]
     "<%Xi;Gamma,Delta|- mu alpha, < u | mu(x,y), < v | alpha > > : subst [u,cv] N_cv%>"
 end}

{let sep = `Mm 2. in
 figurerules ~label:f_dll ~caption:"Dependent {muname} with dependent elimination" [
   (* simple_block "Syntax" begin *)
   (*   syntax [ *)
   (*     syntax_line `Term Rules.Syntax.(core@shift@multiplicative@additive@exponential); *)
   (*     commands *)
   (*   ] *)
   (* end; *)
   simple_block "Reduction" begin
     reduction Rules.Reduction.(core@shift@multiplicative@additive@exponential)
   end;
(*
   simple_block "Derived syntax" begin
     array [`L; symbsep $=$; `L] [
       array_line ["<%lambda x,t%>";"<%mu(x,alpha),<t|alpha>%>"];
       array_line ["<%t u%>"; "<%mu alpha, <t|(u,alpha)>%>"];
       array_line ["<%{1=t,2=u}%>"; "<%{mu(1.alpha),<t|alpha> , mu(2.alpha),<u|alpha>}%>"];
       array_line ["<%t.1%>"; "<%mu alpha,<t|1.alpha>%>"];
       array_line ["<%t.2%>"; "<%mu alpha,<t|2.alpha>%>"];
     ]
   end; *)
   block "Typing" [`C;`C] begin
     let open Rules.Typing.Dll1 in
         [
           block_line ~sep [ id ; cut ];
           block_line ~sep [ iddup ; mu ];
           block_line ~sep [ shiftn ; shiftp ; ];
           block_line ~sep ~sync:false [ pair ; empty ];
           block_line ~sep ~sync:false [ empty ; copair ];
           block_line ~sep [ unit ; counit ];
           block_line ~sep [ iota1 ; case ];
           block_line ~sep [ iota2 ; empty];
           block_line ~sep [ zero ; emptycase ];
           block_line ~sep [ bang ; whynot ];
         ]
   end;
(*
   block "Derived typing rules" [`C;`C] begin
     let open Rules.Typing.Mall in
         [
           block_line ~sep [ lambda ; app ];
           block_line ~sep [ record ; pi1 ];
           block_line ~sep [ empty  ; pi2 ];
         ]
   end;
*)
 ]}
The full system can be found in Figure~{ref_ f_dll}. Let us illustrate dependent {muname} further by showing the rules for dependent product of duplicable terms. That is, the typing derivation for <%lambda|_x_|, t%> which is defined (see Section~{ref_ ss_patterns}) as
<%mu(|_x_|,alpha),<t|alpha> = mu(beta,alpha), <beta|mu|_x_|, <t|alpha>>%> (using shortcut rules for variables as in Section~{ref_ ss_patterns}, the shortcut omit type well-formedness verification):
{let open Infer in
 displaymath begin
   rule ~label:tensor
     [rule ~label:(cutp"<%beta%>")
         [rule ~label:whynotrule
            [rule ~label:(cutp"<%alpha%>")
                ["<%Xi,x:A;|- t : subst [|_x_|,cv] \(N_cv\)%>"]
                "<%Xi,x:A;alpha:subst [|_x_|,cv] \(N_cv\)^~|- <t|alpha>%>"]
            "<%Xi;alpha:\(N_cv\)^~|-mu|_x_|, <t|alpha> : ?A^~%>"]
         "<%Xi;beta:!A,alpha:subst [beta,cv] \(N_cv\)^~|-<beta|mu|_x_|, <t|alpha>>%>"]
     "<%Xi;|-mu(beta,alpha), <beta|mu|_x_|, <t|alpha>> : PI beta:!A, subst[beta,cv]N_cv%>"
end}
As it happens this is not exactly the rule of dependent product in {lambda}-calculus. Namely, all the free variables in a type are of the form <%|_x_|%> while it is not necessarily the case of bound variables. Remember, however, from Section~{ref_ ss_lj} how intuitionistic conjunction and disjunction could be encoded as <%!A<*>!B%> and <%!A<+>!B%> respectively. Encoding of intuitionistic positive connectives require a strict interleaving of linear positive connectives and the duplicability modality. This is essentially the same phenomenon which is reflected in the duplicable dependent product rule.

As a last example, let us return to the equality example of the beginning of the present section. We promised a proof derivation for:
{displaymath"<%PI x:A<*>B, shiftp SIGMA y:A, SIGMA z:B, x=(y,z)%>"}
This sort of statement is quite precisely what dependent elimination provides. A derivation of this statement can be found in Figure~{ref_ f_depelimeq}
{figure begin
 let open Infer in
 displaymath begin
   rule ~label:lambda
     [rule ~label:mu
         [rule ~label:(cutp"<%x%>")
             [rule ~label:parr
                 [rule ~label:(cutp"<%alpha%>")
                     [rule ~label:positiveshift
                         [rule ~label:tensor
                             [rule ~label:idrule [] "<%;;y:A |-_v y : A%>";
                              rule ~label:tensor
                                [rule ~label:idrule [] "<%;;z:B |-_v z : B%>";
                                 rule [] "<%;;|-_v refl : (y,z)=(y,z) %>"]
                                "<%;;z:B |-_v (z,refl) : SIGMA z':B, (y,z)=(y,z') %>"]
                             "<%;;y:A,z:B |-_v (y,(z,refl)) : SIGMA y':A, SIGMA z':B, (y,z)=(y',z') %>"]
                         "<%;y:A,z:B |- val (y,(z,refl)) : shiftp SIGMA y':A, SIGMA z':B, (y,z)=(y',z') %>"]
                     "<%;y:A,z:B,alpha:(shiftp SIGMA y':A, SIGMA z':B, (y,z)=(y',z'))^~|- < val (y,(z,refl))|alpha >%>"]
                 "<%;alpha:(shiftp SIGMA y:A, SIGMA z:B, cv=(y,z))^~|- mu (y,z), < val (y,(z,refl))|alpha > : A^~`&B^~%>"]
             "<%;x:A<*>B,alpha:(shiftp SIGMA y:A, SIGMA z:B, x=(y,z))^~|- < x | mu (y,z), < val (y,(z,refl))|alpha > > %>"]
         "<%;x:A<*>B|- mu alpha, < x | mu (y,z), < val (y,(z,refl))|alpha > > : shiftp SIGMA y:A, SIGMA z:B, x=(y,z)%>"]
     "<%;|-lambda x, mu alpha, < x | mu (y,z), < val (y,(z,refl))|alpha > > : PI x:A<*>B, shiftp SIGMA y:A, SIGMA z:B, x=(y,z)%>"
 end
end ~label:f_depelimeq ~caption:"Derivation of an equality result with dependent elimination"}
Note the necessary step which uses the cut variable, without the cut variable the derivation is no longer valid (in weak dependent {muname}, the cut rule would lead to  <%;;|-refl:x=(y,z)%>, which is certainly an underivable sequent).

There is a limit to dependent {muname}, however: it does not enjoy subject reduction. This is due to the fact that commutative cuts are simply reductions in {muname}. Commutative conversion are not usually correct in dependently typed languages with dependent elimination (though there are much more many correct commutative conversion with Coquand elimination than with Paulin elimination).

As we have seen above, elimination of a value of tensor type can be given the following (specialised) type:
{let open Infer in
 displaymath begin
   rule
     ["<%Xi;Gamma;Delta|-_v u : A<*>B%>";
      "<%Xi;Gamma,x:A,y:B|- v : \(subst [(x,y),cv] \(C_cv\)\) -o subst [(x,y),cv] \(N_cv\)%>"]
     "<%Xi;Gamma,Delta|- mu alpha, < u | mu(x,y), < v | alpha > > : \(subst [u,cv] \(C_cv\)\) -o subst [u,cv] N_cv%>"
 end}
With <%Xi;Gamma,Delta;Pi|-_v t : \(subst [u,cv] \(C_cv\)\)%> we have
{displaymath"<%Xi;Gamma,Delta,Pi|-(mu alpha, <u|mu(x,y),<v|alpha>>) t:subst[u,cv]N_cv%>"}

However, the application <%(mu alpha, <u|mu(x,y),<v|alpha>>) t%> reduces (against an arbitrary context) to <%mu alpha,<u|mu(x,y), <v|(t,alpha)>>%> (see Section~{ref_ ss_optim}). And, unfortunately, the latter is not necessarily well-typed. For it to be well-typed we need a stronger statement on <%t%>:
{displaymath${forall}"<%v%>""<%Psi%>", ("<%Xi;Gamma;Psi|-v:A<*>B%>"){rightarrow}("<%Xi;Gamma,Psi;subst [v,cv] Pi_cv |- t : subst [v,cv] C_cv%>")$}
If <%t%> has such types, then in particular <%Xi;Gamma,x:A,y:B;subst [(x,y),cv] Pi_cv |- t : subst [(x,y),cv] C_cv%>, which will be the proof obligation since dependent elimination takes care of evolving the <%Pi_cv%> context through the proof.

Not all values are as such, however, and subject reduction may indeed fail. To fix subject reduction, we would need to rely on a more involved mechanism than simple substitutions to specialise the context. Some sort of equality constraints would probably work.

However, the lack of subject reduction is not necessarily bad. Indeed, if <%u%>, above, is of the form <%(a,b)%> (which every closed <%u%> is), then <%mu alpha,<(a,b)|mu(x,y), <v|(t,alpha)>>%> further reduces to <%mu alpha, <subst [a,x;b,y] v|(t,alpha)>%> which has indeed the appropriate type. So, at least for closed terms, a failure of subject reduction can be fixed by additional reductions. This sort of type safety property can be proved using Krivine realisability~{cite"Munch2009"}. Such a proof is left to future work, so let it be the last act of this article to state the following conjecture:

{let conj ?name x =
   let opt = match name with Some n -> Some(T,n) | None -> None in
   environment\"conj\" ?opt (T,x) T in
 conj ~name:"Type safety" begin
   "For any closed term <%;|-t:N%> of negative type, the normal form <%c%> of the command <%<t|alpha>%> has type <%;alpha:N^~|-c%>."
 end}

(* some prototypes of proofs for the subject reduction issue
{tiny begin
 let open Infer in
 displaymath begin
   rule ~label:mu
     [rule ~label:cutrule
         ["<%Xi;Gamma;Delta|-_v u : A<*>B%>";
          rule ~label:parr
            [rule ~label:cutrule
                ["<%Xi;Gamma,x:A,y:B|- v : \(subst[(x,y),cv] C_cv\) -o \(subst[(x,y),cv] N_cv\)%>";
                 "<%Xi;Gamma,x:A,y:A;Pi,alpha:\(subst[(x,y),cv] N_cv\)^~|-_v (t,alpha) : X%>"]
                "<%Xi;Gamma,Pi,x:A,y:B,alpha:\(subst[(x,y),cv] N_cv\)^~|- <v|(t,alpha)>%>"]
            "<%Xi;Gamma,Pi,alpha:\(N_cv\)^~|- mu(x,y), <v|(t,alpha)> : A^~`&B^~%>"]
         "<%Xi;Gamma,Delta,Pi,alpha:\(subst[u,cv]N_cv\)^~|-<u|mu(x,y), <v|(t,alpha)>>%>"]
     "<%Xi;Gamma,Delta,Pi|-mu alpha,<u|mu(x,y), <v|(t,alpha)>> : subst[u,cv]N_cv%>"
 end
end}

Shorter problem: <%< t | mu alpha,<u|mu beta,<v|beta> > >%> vs <%< u | mu beta, <v|t>>%>
*)

"
